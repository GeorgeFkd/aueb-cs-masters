\documentclass{article}
\usepackage{titling,titlesec,tikz,amsmath,amssymb}
\usepackage[dvipsnames]{xcolor}
\newcommand{\note}[1] {
	\textcolor{Purple}{#1}

}

\title{Practical Runtime Verification of Performance in event based systems using Metric Temporal Logic}

\author{George Fakidis}

\begin{document}
\maketitle
\begin{abstract}
	Event Based Systems(EBS) are the foundation of modern cloud system infrastructure. Event Driven Architecture(EDA) is a scalable architectural pattern that enables operations at an unprecedented scale. Performance considerations are of utmost importance to ensure cost efficiency and achieving QoS guarantees. In this paper we formalise performance [profiling] of events, in a manner that allows us to reuse existing methodologies and algorithms. We show that performance monitoring of series of events can be reduced to a problem of checking the temporal constraints of the events under study using (event logs). We also create a preliminary tool to integrate this runtime verification into existing technology stacks.
\end{abstract}


\section{Introduction}

\note{Will be written last}

Software Systems have grown considerably in the last years, and are now used in critical sectors like 1,2,3.
Modern large scale systems serve millions of users and execute billions of operations per second.
To enable computation at this unprecedented scale, sophisticated scalable architectures are required.
One of the most popular and widely adopted is Event-Driven Architecture that centers its attention to messages sent between different systems in order to complete the desired computations.
Therefore it is necessary to reason about the performance and correctness software and systems in a manner that can provide guarantees and be relied upon. Event-based systems are complex due to the flexible,unspecified and asynchronous interactions they enable and thus require expressive specification techniques that can be checked at runtime.
\par
[This will be written from Wikipedia and mb a couple foundational papers] Formal Methods are a set of mathematical tools that enable us to reason about software in a complete, sound and verifiable manner using specifications that can be checked rigorously. Formal Methods that pursue completeness can sometimes be unapplicable in certain cases such as 1,2,3. Runtime verification uses data generated by a running system(traces) in order to detect violations of expressed properties and tries to provide guarantees for the system being studied.

\par
A bit more detail of what event-based systems are, how do they look in practice(w. diagrams and a simple example).


\par
Performance in Event-Based Systems can be more precisely expressed as:
\begin{itemize}
	\item Throughput
	\item Latency
\end{itemize}

\par
A brief explanation of Metric Temporal Logic(MTL) and some visual examples and the intuition behind its operators. The paper [Distributed Runtime Verification of metric temporal properties] has a nice paragraph on this, I can write something similar with extra shapes to indicate the intuition.


\section{Related Work}

\note{Will be written after i do the core of the work below}

\subsection{Temporal Logic in Event-Based Systems}
\subsection{Performance in Event-Based Systems}
\begin{itemize}
	\item How is Performance Measured in Event-Based/Event-Driven Systems?
	\item How are QoS guarantees made in such systems (at a model level)?
	\item What formal Methods are used in such tasks?
\end{itemize}


\subsection{Quantitative Formal Methods for Event-Based Systems }
Formal Methods used in other works.
\begin{itemize}
	\item UPAAL
	\item PRISM
	\item Markov Chains (of Discrete or Continuous time)
	\item Timed Temporal Logics (TTL $\rightarrow$ TCTL,MTL)
	\item Probabilistic Temporal Logics (PCTL, PLTL)
	\item Petri nets
\end{itemize}

\section{Formalising Event-Based Systems}
We borrow formalisations for Workflows,"Enactments",Activities and Events from the work of [Early Detection of temporal constraint violations]. Briefly explained, Workflows are an abstract series of abstract events/activities, that have a {\it start} event and possibly multiple {\it end} events. (In a software engineering context, workflows are similar to). Activities are the lowest level building block, denoting a unit of work in workflow. Events are generated by the execution of an activity. {\it Enactments} are the result of a concrete execution of workflow. In order to be able to distinguish between different executions of the same workflow, enactments also include an ID. This ID is included in events generated by activities execution in an enactment. In practice, this ID could be a user's ID that is carried throughout the workflow, thus allowing us to specify and monitor performance properties for the specific sequence of events while the model remains abstract and generic.

\par
Using the definitions explained above, performance in this paper is regarded as the difference between event timestamps
in order to keep the model simple.
In future work, that difference between event timestamps could be analysed in a more granular level,for example dividing the time required for responding to an event into network latency, database latency and processing latency.

\section{Formal properties in MTL}

\note{From the non my work stuff this will come first as it is important}
Metric Temporal Logic can be used as a specification language to specify desired properties of an event-based system.
When attempting to specify formal properties in a non-trivial software system it is important to understand {\it Safety} and {\it Liveness} properties[Lamport, On proving the correctness of multiprocess (concurrent) programs], a distinction practically useful.
Safety is about checking whether {\it bad things} happen, it is about prohibiting invalid behaviour, thus only allowing for safe states throughout execution.

Liveness is about checking {\it good things} that must happen during an execution. It is important to note that the thing we check can involve an infinite number of steps.

Generally it is more difficult to specify and check liveness properties than safety properties[citation needed].


In the context of an event-based system we provide some indicative properties we would want to check. This will be made into a table that specifies what we want to check and the related MTL formula.
\begin{itemize}
	\item Event A should always be followed by Event B within a certain time.
	\item Event A should be responded with Event B or Event C within a certain time(useful to specify where failures can happen and how).
	\item Event A should happen periodically.
	\item Event chains, e.g. Event A should be followed by Event B which should then be followed by Event C or Event D. This is especially useful when checking that execution of workflows, as defined above, conform to performance standards.
	\item For integrity reasons an Event B should not happen if an Event A has not come before that.
	\item Event A and Event B should not happen until another event happens.
\end{itemize}
In a practical scenario, the above properties will represent policy that must be adhered to by the implemented software.

I will write some simple things we usually test in such systems.

\section{Integration of verification process into running EBS}
\note{This section will probably be done after everything as it is a bit optional now that i think about it}
\section{Software Solution Discussion}
\note{This will be written first as it is the core of my work}
In this section we will talk more in detail about how to implement runtime verification of performance using metric temporal logic.
\subsection{Technical Requirements}
For a system component that brings runtime verification capabilities

\subsection{Design Goals}
The target software architecture we intend to verify is Event-Driven Architecture(EDA), therefore any stated desired goal
should consider the constraints of a distributed event-driven architecture.

We outline the following Design Goals and explain them more in detail.

\begin{itemize}
	\item Online execution for real-time violation reports.
	\item Integration with the existing event-driven ecosystem.(Ease of Integration with a new system)
	\item Horizontal Scalability
	\item System Independent
	\item Performance
\end{itemize}


\par
\emph{Online execution} is important as the order of magnitude of the data an offline algorithm would need to store is impractical.
It also provides valuable timely feedback, useful for addressing performance issues early on and avoiding costly downtimes.
Finally the runtime verification problem by its very nature is more accurately expressed by online algorithms, an offline mode
would not differ significantly from a simple constraint checking problem using the system logs. In this paper, we focus on the online case.
\par
Being \emph{system independent} practically means that the solution does not have a model of the underlying system, only a generic view of it.
Decoupling from a concrete implementation is necessary, due to the fact that in EDA, the only common denominator between different systems
is the Event Bus, which is also further segmented into different independent topics. Assuming a specific technology stack is an approach that
is unrealistic for complex large-scale systems.
\par
\emph{Performance} is important to the degree that existing systems are not affected by the addition of the monitoring component into the system.
As with all performance measurement tools its resource consumption should be a negligible fraction of the total resource consumption of the system.
Data structures and algorithms should be carefully considered to achieve low time and space complexity. Such large-scale systems operate on the order
of magnitude of billion operations processed per second thus complexity is crucial in practice.
\par
For verification to be practical it should be close to the software development process and not implemented in a separate isolated tool.
Instead, a solution should be part of the suite of tools that is already used in EDA systems. This way not only the functionality is
easier to adopt in the software development process, but also benefits from a rich ecosystem to support it.


\note{Ensure that horizontal scalability and vertical scalability is properly explained}
\par
Horizontal scalability is one of the main features of EDA and thus the monitoring component should be able to operate in a distributed manner.
Vertical scalability is impractical for systems operating at this scale.
\subsection{Proposed Architecture}
\section{Proof of Concept Demonstration}
\note{This should be around 2-3 days of intense focused work, I will go TDD in order to have the infra ready to produce the results}
First will come a couple lines of a few implementation details. I will make it in python, where each service is a Kafka Consumer/Producer and I will have an API that I will run where the client will submit his request.

The way i will demonstrate that my system works is the following, each request being processed will have a small percentage of "failure", in our case a thread.sleep() command that makes our system slower than usual and thus fail the runtime verification test. What we want to observe is that our system can catch these scenarios.
\subsection{Case Study}
\note{This mostly revolves around writing the case study and doing the graphic}
This is where i will present the case study that i will then run as an example.
I will attempt to make my case study more complex in order to encapsulate more types of temporal properties demonstrated.
Using my software to do the verification. I will probably do an integrated e-commerce system: User clicks pay, payment event is emitted, payment event does the processing and emits payment completed or payment failed due to lack of funds.

The payment completed event is consumed by a notification system that sends an email to the user, and by a supply chain software that updates the inventory and emits an inventory update event.

The payment completed event is also consumed by the shipment delivery system that adds a new shipment to be done, emitting a NewShipment event that within some time also emits a ShipmentScheduled event that notifies the user when the package ordered will arrive. Finally when the user receives the package, the person reponsible for its delivery submits a Shipment Completed Event.


\note{Write those in metric temporal logic.}

The diamond is a bit small for some reason
$\diamond$
$\square$
$\triangle$
Things I want to check:
\begin{enumerate}
	\item After the user paying, a payment completed or a payment failed event arrives in X time
	\item Succession of events in a timely manner(in the happy path and the simple failure path)
	\item If a user clicks twice for the same payment that only one payment completed event is fired and user was not doubly charged(this is more of a logic thing than a performance thing).
	\item No items should arrive without a Shipment Scheduled event before them (ensuring process efficiency and integrity).
	\item If the user specified same day delivery, the Shipment Completed Event should be within 24 hours of the payment completed event.
\end{enumerate}

I will make a simple diagram (as a pdf), that i will include here, to showcase the different services, and the events through which they communicate.

\subsection{Results}
This is where i will put the results. Each scenario will be a sequence of events that we want to check and we will be subscribing to all topics we need to.
Results will be of the form: Table of Scenarios, Detected by our program or not.

\section{Future Work}
\begin{itemize}
	\item Responding Online(Autoscaling?) to violations of metric temporal properties
	\item Synchronising Automatic Test Generation and Runtime Verification Monitor Generation from metric temporal properties in order to integrate performance checking in both development and production environments.
	\item Generating Metric Temporal Properties from event logs using process mining.
\end{itemize}



\end{document}
