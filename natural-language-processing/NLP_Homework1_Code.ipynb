{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Κώδικας Ομάδας NLP: Φακίδης Γιώργος, Πέτρος Φίλος, Γιώργος Βιδάκης"
      ],
      "metadata": {
        "id": "a5DmRx40j2pn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup Code to Run the Code Below"
      ],
      "metadata": {
        "id": "3QhnkFzICiy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install evaluate # For WER,CER metrics"
      ],
      "metadata": {
        "id": "2Lv_UbcqCBW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a194442-7d96-4697-ed55-9038b12b3ac0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.10)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install jiwer"
      ],
      "metadata": {
        "id": "J_iPaGn0CCV9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6cfdc5b-f3f8-4f81-c281-7e339a25b294"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jiwer\n",
            "  Downloading jiwer-3.0.5-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n",
            "Requirement already satisfied: rapidfuzz<4,>=3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (3.10.1)\n",
            "Downloading jiwer-3.0.5-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: jiwer\n",
            "Successfully installed jiwer-3.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Levenshtein"
      ],
      "metadata": {
        "id": "3DgI27PTCHzS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71fee76b-e418-47cd-f823-bcfeb21aa224",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Levenshtein\n",
            "  Downloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein)\n",
            "  Downloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Downloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein\n",
            "Successfully installed Levenshtein-0.26.1 rapidfuzz-3.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from collections import Counter\n",
        "\n",
        "from nltk.corpus import brown, stopwords,europarl_raw,abc\n",
        "from nltk import tokenize, sent_tokenize, unique_list, word_tokenize\n",
        "nltk.download(\"brown\")\n",
        "nltk.download(\"europarl_raw\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('punkt')\n",
        "nltk.download(\"abc\")\n",
        "from nltk.util import ngrams\n",
        "from Levenshtein import distance\n",
        "import string\n",
        "import numpy as np\n",
        "import random\n",
        "from evaluate import load\n",
        "from math import log2\n",
        "import math\n",
        "\n",
        "from nltk.corpus import brown, stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize"
      ],
      "metadata": {
        "id": "DfSncoPzkBm1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fa0758d-c2e2-4bff-faf8-12f96254cbd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package europarl_raw to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/abc.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1) Implement (in any programming language) a bigram and a trigram language model for sentences, using Laplace smoothing\n"
      ],
      "metadata": {
        "id": "Hx8PqhkWCn88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "obj_corpus_reader_category_text = brown.words(categories=\"news\")\n",
        "list_corpus_text = list(map(lambda var_token: var_token.lower(), obj_corpus_reader_category_text))\n",
        "\n",
        "var_split_index = int(len(list_corpus_text)* 0.8)\n",
        "var_check_increase_index = 4\n",
        "var_split_index += var_check_increase_index\n",
        "print(\"Splitting index point is:\", var_split_index, \"Total length is:\", len(list_corpus_text))\n",
        "# for var_index in range(var_split_index,len(list_corpus_text)):\n",
        "#     print(list_corpus_text[var_index])\n",
        "# <000000000000000000000 0000000000000000000000000>\n",
        "list_test_corpus = list_corpus_text[var_split_index:]\n",
        "list_corpus_text = list_corpus_text[:var_split_index]\n",
        "\n",
        "print(\"Training List: Length with stopwords:\", len(list_corpus_text))\n",
        "print(\"Testing List:  Length with stopwords:\", len(list_test_corpus))\n",
        "# Stopwords δεν χρειάζονται σε κάποιες περιπτώσεις π.χ. θέλει classification\n",
        "list_corpus_text = [var_token for var_token in list_corpus_text if not var_token in stopwords.words(\"english\")]\n",
        "list_test_corpus = [var_token for var_token in list_test_corpus if not var_token in stopwords.words(\"english\")]\n",
        "\n",
        "print(\"Reader Object: Length of Corpus is:\", len(obj_corpus_reader_category_text), \"First tokens are:\", obj_corpus_reader_category_text[:20])\n",
        "print(\"Training List: Length of Corpus is:\", len(list_corpus_text), \"First tokens are:\", list_corpus_text[:20])\n",
        "print(\"Testing List:  Length of Corpus is:\", len(list_test_corpus), \"First tokens are:\", list_test_corpus[:20])\n",
        "\n",
        "obj_collections_counter = Counter(list_corpus_text)\n",
        "print(\"Length of Counter is:\", len(obj_collections_counter))\n",
        "# Filter out words that do appear less than 9 times\n",
        "obj_collections_counter = Counter({var_key: var_value for var_key, var_value in obj_collections_counter.items() if var_value > 9})\n",
        "print(\"Length of Counter is:\", len(obj_collections_counter))\n",
        "print(\"Most common are:\", obj_collections_counter.most_common(10))\n",
        "print(\"Least common are:\", obj_collections_counter.most_common()[-10:])\n",
        "\n",
        "dict_keys_vocabulary = obj_collections_counter.keys()\n",
        "print(\"Length of Vocabulary:\", len(dict_keys_vocabulary), \"Type:\", type(dict_keys_vocabulary))\n",
        "\n",
        "list_corpus_text = [var_token if var_token in dict_keys_vocabulary else \"<UNK>\" for var_token in list_corpus_text]\n",
        "print(\"Length of Corpus with unknown words replaced:\", len(list_corpus_text))\n",
        "\n",
        "# From 3.8.2 nltk version, \"punkt\" is replaced by \"punkt_tab\".\n",
        "# download_nltk_data_resources(\"punkt\")\n",
        "# download_nltk_data_resources(\"punkt_tab\")\n",
        "counter_unigram = Counter()\n",
        "counter_bigram = Counter()\n",
        "counter_trigram = Counter()\n",
        "\n",
        "var_training_text = \" \".join(list_corpus_text)\n",
        "list_train_sentences = sent_tokenize(var_training_text)\n",
        "var_testing_text = \" \".join(list_test_corpus)\n",
        "# list_test_sentences = sent_tokenize(var_testing_text)\n",
        "\n",
        "\n",
        "print(type(list_train_sentences))\n",
        "\n",
        "for var_sent in list_train_sentences:\n",
        "    counter_unigram.update([var_unigram for var_unigram in ngrams(var_sent.split(), 1, pad_left = True, pad_right=True, left_pad_symbol = \"<start>\", right_pad_symbol=\"<end>\")])\n",
        "    counter_bigram.update([var_bigram for var_bigram in ngrams(var_sent.split(), 2, pad_left = True, pad_right=True, left_pad_symbol = \"<start>\", right_pad_symbol=\"<end>\")])\n",
        "    counter_trigram.update([var_trigram for var_trigram in ngrams(var_sent.split(), 3, pad_left = True, pad_right=True, left_pad_symbol = \"<start>\", right_pad_symbol=\"<end>\")])\n",
        "\n",
        "print(counter_unigram.most_common(10))\n",
        "print(counter_bigram.most_common(10))\n",
        "print(counter_trigram.most_common(10))\n",
        "print(counter_bigram.most_common()[-10:])\n",
        "print(type(counter_unigram))\n",
        "\n",
        "dict_counter_unigrams = {var_key[0]: var_value for var_key, var_value in counter_unigram.items()}\n",
        "dict_counter_unigrams.update({\"<start>\": len(list_train_sentences)})\n",
        "dict_counter_bigrams = {(var_key[0], var_key[1]): var_value for var_key, var_value in counter_bigram.items()}\n",
        "dict_counter_bigrams.update({(\"<start>\",\"<start>\"): len(list_train_sentences)})\n",
        "dict_counter_trigrams = {(var_key[0], var_key[1], var_key[2]): var_value for var_key, var_value in counter_trigram.items()}\n",
        "# print(dict_counter_unigrams)\n",
        "# print(dict_counter_bigrams)\n",
        "# print(dict_counter_trigrams)\n",
        "\n",
        "print(\"keys are:\", dict_counter_unigrams.keys())\n",
        "print(\"count is:\", dict_counter_unigrams['<start>'])\n",
        "\n",
        "\n",
        "var_vocabulary_size = len(dict_keys_vocabulary)\n",
        "print(\"vocabulary size is:\", var_vocabulary_size)\n",
        "dict_bigram_probabilities = { }\n",
        "for var_bigram_key, var_bigram_value in dict_counter_bigrams.items():\n",
        "    #print(\"var_bigram_key is:\", var_bigram_key, \"with value:\", var_bigram_value)\n",
        "    #print(\"count of:\", var_bigram_key[0], \"is: \", dict_counter_unigrams.get(var_bigram_key[0]), \"is there in vocabulary:\", var_bigram_key[0] in dict_keys_vocabulary)\n",
        "    #Formula for Bigram Language Model using Laplace Smoothing\n",
        "    dict_bigram_probabilities.update({(var_bigram_key[1], var_bigram_key[0]): (var_bigram_value + 1) / (dict_counter_unigrams[var_bigram_key[0]] + var_vocabulary_size)})\n",
        "\n",
        "dict_trigram_probabilities = { }\n",
        "for var_trigram_key, var_trigram_value in dict_counter_trigrams.items():\n",
        "    #Formula for Trigram Language Model using Laplace Smoothing\n",
        "    dict_trigram_probabilities.update({(var_trigram_key[2], var_trigram_key[0], var_trigram_key[1]): (var_trigram_value + 1) / (dict_counter_bigrams[(var_trigram_key[0],var_trigram_key[1])] + var_vocabulary_size)})\n",
        "\n",
        "\n",
        "# print(dict_bigram_probabilities)\n",
        "# print(dict_trigram_probabilities)"
      ],
      "metadata": {
        "id": "Hu-uyXfZBVwU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01335393-fc96-4025-a151-0dba6f259c9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splitting index point is: 80447 Total length is: 100554\n",
            "Training List: Length with stopwords: 80447\n",
            "Testing List:  Length with stopwords: 20107\n",
            "Reader Object: Length of Corpus is: 100554 First tokens are: ['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that']\n",
            "Training List: Length of Corpus is: 51217 First tokens are: ['fulton', 'county', 'grand', 'jury', 'said', 'friday', 'investigation', \"atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'evidence', \"''\", 'irregularities', 'took', 'place', '.', 'jury']\n",
            "Testing List:  Length of Corpus is: 12522 First tokens are: ['show', 'self-restraint', ',', 'get', 'orders', '.', 'circumstances', ',', 'protection', 'relatively', 'small', 'manufacturers', 'engage', 'exactly', 'kind', 'conspiracy', 'giants', 'latter', 'convicted', '.']\n",
            "Length of Counter is: 11339\n",
            "Length of Counter is: 881\n",
            "Most common are: [(',', 4048), ('.', 3234), ('``', 602), (\"''\", 580), ('said', 373), ('mrs.', 253), (';', 220), ('--', 210), ('would', 209), ('new', 192)]\n",
            "Least common are: [('skorich', 10), ('california', 10), ('arnold', 10), ('hall', 10), ('makes', 10), ('food', 10), ('designs', 10), ('died', 10), ('investment', 10), ('huff', 10)]\n",
            "Length of Vocabulary: 881 Type: <class 'dict_keys'>\n",
            "Length of Corpus with unknown words replaced: 51217\n",
            "<class 'list'>\n",
            "[(('<UNK>',), 21785), ((',',), 4048), (('.',), 3234), (('``',), 602), ((\"''\",), 580), (('said',), 373), (('mrs.',), 253), ((';',), 220), (('--',), 210), (('would',), 209)]\n",
            "[(('<UNK>', '<UNK>'), 9449), (('.', '<end>'), 3225), (('<UNK>', ','), 2327), ((',', '<UNK>'), 2107), (('<start>', '<UNK>'), 1605), (('<UNK>', '.'), 1469), (('``', '<UNK>'), 353), (('<UNK>', \"''\"), 334), ((\"''\", '.'), 239), (('<start>', '``'), 210)]\n",
            "[(('<UNK>', '<UNK>', '<UNK>'), 4118), (('.', '<end>', '<end>'), 3225), (('<start>', '<start>', '<UNK>'), 1605), (('<UNK>', '.', '<end>'), 1465), (('<UNK>', ',', '<UNK>'), 1275), (('<UNK>', '<UNK>', ','), 1081), ((',', '<UNK>', '<UNK>'), 965), (('<start>', '<UNK>', '<UNK>'), 782), (('<UNK>', '<UNK>', '.'), 758), ((',', '<UNK>', ','), 295)]\n",
            "[(('business', 'must'), 1), (('lines', ';'), 1), ((';', 'must'), 1), (('game', 'never'), 1), (('fact', 'business'), 1), (('public', 'policy'), 1), (('us', 'look'), 1), (('industry', 'general'), 1), (('--', 'whether'), 1), (('prices', 'way'), 1)]\n",
            "<class 'collections.Counter'>\n",
            "keys are: dict_keys(['fulton', 'county', 'grand', 'jury', 'said', 'friday', 'investigation', '<UNK>', 'recent', 'primary', 'election', '``', 'evidence', \"''\", 'took', 'place', '.', 'city', 'executive', 'committee', ',', 'charge', 'atlanta', 'term', 'charged', 'court', 'judge', 'reports', 'possible', 'jr.', 'received', 'interest', 'number', 'voters', 'find', 'many', 'laws', 'legislators', 'act', 'end', 'among', 'well', 'generally', 'best', 'proposed', 'however', 'two', 'greater', 'cost', 'administration', 'department', 'personnel', 'result', 'policies', 'urged', 'take', 'problem', 'law', 'also', 'next', 'legislature', 'provide', 'funds', 'date', 'may', 'state', 'welfare', 'federal', 'services', 'one', 'major', 'general', 'program', 'counties', 'money', 'might', 'feel', 'future', 'receive', 'fire', 'fees', 'found', 'association', 'fact', 'effect', 'costs', 'elected', 'new', 'jan.', '1', 'political', 'added', 'prices', ':', '(', ')', 'four', 'additional', 'medical', 'night', '2', 'work', 'officials', 'pass', 'fair', 'plan', 'operation', 'police', 'tax', 'office', 'hospital', 'health', 'mayor', 'william', 'b.', 'wife', 'williams', 'couple', 'son', 'daughter', 'mrs.', 'j.', 'm.', 'property', 'agreed', 'upon', 'listed', 'attorney', 'together', 'man', 'year', 'home', 'e.', 'aj', 'henry', 'l.', 'since', 'career', 'back', 'council', 'present', 'became', 'candidate', '13', 'announced', 'would', 'run', 'georgia', 'republicans', 'getting', 'strong', 'race', 'top', 'official', 'wednesday', 'robert', 'chairman', 'meeting', 'held', 'tuesday', 'blue', 'brought', 'audience', 'party', 'james', 'w.', '8', 'texas', 'sen.', 'john', 'governor', 'force', 'despite', 'vote', 'according', 'attended', 'asked', 'whether', 'wanted', 'make', '--', 'face', 'says', 'making', 'first', 'must', 'taken', 'five', 'per', 'cent', 'candidates', 'unit', 'system', 'public', 'relations', 'director', 'gov.', 'campaign', 'expected', 'time', 'assistant', 'three', 'years', 'starts', 'become', '1961', 'session', 'monday', 'head', 'bond', 'afternoon', 'senate', 'study', 'rural', 'areas', 'made', 'toward', 'million', 'issue', 'earlier', 'construction', 'bonds', 'near', 'ready', 'worth', 'go', 'test', 'sales', 'authority', 'road', 'fund', 'apparently', 'every', 'old', 'paid', '1958', 'battle', 'told', 'yet', 'plans', 'rep.', 'd.', 'resolution', 'house', 'action', 'day', 'increase', 'sunday', 'research', 'done', 'given', 'worked', 'set', 'similar', 'passed', 'last', 'pay', 'aid', 'education', 'something', 'past', 'support', 'members', 'washington', 'like', 'see', 'event', 'congress', 'board', 'give', 'long', 'school', 'put', 'ever', 'saw', 'davis', 'democratic', 'got', 'order', 'church', 'calls', 'former', 'george', 'p.', 'march', '18', 'days', 'post', 'soon', 'scheduled', 'local', 'good', 'went', 'real', 'austin', 'certain', 'thursday', 'bankers', 'led', 'fight', 'measure', 'hearing', 'rules', 'week', 'left', 'little', '17', 'dollars', 'help', 'current', 'merely', 'means', 'bank', 'persons', 'seven', 'bill', 'firms', 'companies', 'report', 'cannot', 'almost', 'declared', 'lawrence', 'charles', 'hughes', 'amount', 'several', 'including', 'jones', 'houston', 'howard', 'probably', 'enough', 'dallas', 'schools', 'designed', 'special', 'students', 'agency', 'children', '6', 'attend', \"year's\", 'estimated', 'coming', 'live', 'get', 'hear', 'still', 'tell', \"'\", 'letters', 'believe', 'people', 'better', 'question', 'san', 'heard', 'proposal', 'although', 'later', 'sent', 'planning', 'bills', 'passing', 'another', 'district', 'third', 'adopted', 'without', 'a.', 'r.', 'coast', 'louis', 'group', 'taxes', 'return', 'plus', 'fine', 'series', 'league', 'annual', 'gas', 'right', 'frank', '3', 'commission', 'need', 'chief', 'decided', 'taking', 'kind', 'kept', 'april', '4', 'u.s.', 'senator', 'west', 'reported', '22', 'final', 'information', 'except', 'water', 'big', 'development', 'effort', 'could', 'project', 'large', 'felt', 'spent', 'statements', 'attack', 'de', 'f.', 'c.', 'history', '12', 'hours', 'teaching', 'junior', 'high', 'college', '30', 'least', 'person', 'joined', 'dr.', 'president', 'university', '&', 'addition', 'island', 'team', 'football', 'served', 'corps', 'army', 'called', 'yesterday', 'york', 'firm', '10', 'case', 'serious', 'family', 'martin', 'co.', 'problems', 'cases', 'community', 'able', 'limited', 'living', 'trial', 'defense', 'six', 'eight', 'grant', 'request', 'indicated', 'others', '?', 'honor', 'kennedy', 'today', 'white', 'business', 'working', 'address', 'tomorrow', 'american', 'television', 'much', 'summer', 'returned', 'way', 'press', 'secretary', 'say', 'staff', 'involved', 'rather', 'meet', 'matter', 'even', '200', 'building', 'used', 'outside', 'room', 'actually', 'east', 'st.', 'statement', '9', 'care', 'social', 'security', 'workers', 'americans', 'railroad', 'programs', 'grants', '20', 'hill', 'payroll', 'already', 'billion', 'higher', 'full', 'nine', 'following', 'use', 'part', 'service', 'states', 'stay', 'cut', \"president's\", 'student', 'needed', 'young', 'going', \"can't\", 'government', 'area', 'field', 'national', 'along', 'lines', 'republican', 'leader', 'thing', 'tonight', 'housing', '11', 'floor', 'record', 'immediate', 'rule', 'hour', 'demand', 'north', 'organization', 'foreign', 'changes', 'particularly', 'never', 'weeks', 'ago', 'walk', 'policy', 'cars', 'daily', 'line', 'side', 'united', 'leadership', 'mr.', 'soviet', 'came', 'individual', 'gave', 'months', 'nuclear', 'union', 'stand', 'achievement', 'perhaps', 'around', 'spring', 'within', 'economic', 'countries', 'forces', 'come', 'conference', 'laos', 'military', 'interested', 'international', 'communist', 'south', 'possibility', 'control', 'world', 'richard', 'situation', 'power', 'country', 'morton', 'boston', 'groups', ';', 'efforts', 'america', 'early', 'eisenhower', 'period', 'negotiations', 'far', 'nations', 'show', 'great', 'want', 'war', 'favor', 'spirit', '25', 'half', 'growth', 'labor', 'david', 'youth', 'sense', '1959', 'providence', 'civil', 'h.', 'hawksley', 'salary', 'basis', 'job', 'men', 'equipment', 'central', 'station', 'section', 'know', 'point', 'theater', 'air', 'vital', 'call', 'level', 'name', 'move', 'form', 'miss', 'mary', 'complete', 'gen.', 'joseph', 'religious', 'officers', 'across', 'times', 'sold', 'foods', 'small', 'parties', 'club', 'luncheon', 'hotel', 'average', 'member', 'victory', 'vice', 'us', 'turned', 'really', 'presented', 'town', 'charter', 'hand', 'explained', 'think', 'running', 'followed', 'started', 'traffic', 'sixth', 'mitchell', 'value', 'using', '100', 'park', 'women', \"he's\", 'fall', 'open', 'industry', 'share', 'income', 'minutes', 'position', 'life', 'leaders', 'failed', 'ave.', 'necessary', 'commissioner', 'appeals', 'jim', 'division', 'private', 'feet', 'keep', 'lives', 'acres', 'land', 'bring', 'honored', 'whose', 'wagner', '7', 'view', 'performance', 'g.', 'june', 'conspiracy', 'beach', 'thomas', 'stage', 'month', 'u.', 's.', 'moscow', 'premier', 'khrushchev', 'look', '!', 'successful', '1960', 'n.', 'professional', 'start', 'decision', 'agreement', 'reached', 'manager', 'company', 'saturday', 'orleans', 'miles', 'avenue', 'street', 'course', 'car', 'center', 'include', 'headed', 'barnett', 'friends', 'smith', 'play', 'though', 'continued', 'tried', 'loss', 'contract', 'philadelphia', 'played', 'appeared', 'charges', 'wide', 'single', 'account', 'formerly', 'owners', 'warren', 'drive', 'driving', 'lee', 'churches', 'second', 'bomb', 'boy', 'wall', 'front', 'away', 'began', 'oct.', 'ap', '15', 'portland', 'father', 'society', 'reason', 'products', 'total', 'ralph', 'thought', 'los', 'jack', 'game', 'dinner', 'p.m.', 'al', 'a.m.', 'rev.', 'opening', 'verdict', 'miami', 'straight', '5', 'late', 'birds', 'hits', 'homer', 'runs', 'winning', 'fashion', 'robinson', 'bob', 'stadium', 'double', 'moved', 'beat', 'ball', 'hit', 'champion', 'yankees', 'players', 'farm', 'art', 'games', 'coach', 'pitching', 'lead', 'condition', 'yards', 'turn', 'season', 'ohio', 'francisco', 'knee', 'chicago', 'moritz', 'cotton', \"that's\", '14', 'seem', 'happy', 'denver', 'baseball', 'trip', 'mantle', 'skorich', 'catholic', 'award', 'california', 'arnold', 'hall', 'husband', 'marriage', 'mother', 'evening', 'bus', 'stein', 'makes', 'stock', 'music', 'orchestra', 'guests', 'black', 'christian', 'shop', 'food', 'driven', 'market', 'secrets', 'designs', 'british', 'arrested', 'machinery', 'august', 'died', 'kowalski', 'collection', 'faculty', 'emory', 'investment', 'hillsboro', 'huff', 'shares', 'gin', 'concert', 'ballet', 'library', '<start>'])\n",
            "count is: 3410\n",
            "vocabulary size is: 881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(2) Estimate the language cross-entropy and perplexity of your two models on a test subset of\n",
        "the corpus, treating the entire test subset as a single sequence of **sentences**"
      ],
      "metadata": {
        "id": "geU_fmfMC2Yk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list_subset_sentences = sent_tokenize(var_training_text)[:10]\n",
        "# Cross Entropy Formulas\n",
        "list_subset_sentences = sent_tokenize(var_testing_text)[:10]\n",
        "var_bigram_sum_log_likelihood = 0\n",
        "var_trigram_sum_log_likelihood = 0\n",
        "var_total_tokens = 0\n",
        "for var_sent in list_subset_sentences:\n",
        "    var_sent_bigram = \"<start> \" + var_sent + \" <end>\"\n",
        "    var_sent_trigram = \"<start1> <start2> \" + var_sent + \" <end>\"\n",
        "    list_sentence_tokens = var_sent_bigram.split()\n",
        "    var_total_tokens += len(list_sentence_tokens)\n",
        "    for var_bigram_token in range(1, len(list_sentence_tokens)-1):\n",
        "        # print(\"token is:\", list_sentence_tokens[var_bigram_token])\n",
        "        # print((list_sentence_tokens[var_bigram_token+1], list_sentence_tokens[var_bigram_token]))\n",
        "        bigram_tuple = (list_sentence_tokens[var_bigram_token+1], list_sentence_tokens[var_bigram_token])\n",
        "        var_bigram_sum_log_likelihood += math.log2(dict_bigram_probabilities.get(bigram_tuple, 1 / (dict_counter_unigrams.get(var_bigram_token, 0.0) + var_vocabulary_size)))\n",
        "\n",
        "    for var_trigram_token in range(2, len(list_sentence_tokens)-2):\n",
        "        bigram_tuple = (list_sentence_tokens[var_trigram_token+1], list_sentence_tokens[var_trigram_token])\n",
        "        trigram_tuple = (list_sentence_tokens[var_trigram_token+2], list_sentence_tokens[var_trigram_token], list_sentence_tokens[var_trigram_token+1])\n",
        "        var_trigram_sum_log_likelihood += math.log2(dict_trigram_probabilities.get(trigram_tuple, 1 / (dict_counter_bigrams.get(bigram_tuple, 0.0) + var_vocabulary_size)))\n",
        "\n",
        "var_bigram_cross_entropy = - var_bigram_sum_log_likelihood / var_total_tokens\n",
        "var_bigram_perplexity = math.pow(2, var_bigram_cross_entropy)\n",
        "var_trigram_cross_entropy = - var_trigram_sum_log_likelihood / var_total_tokens\n",
        "var_trigram_perplexity = math.pow(2, var_trigram_cross_entropy)\n",
        "print(\"Bigram: Cross Entropy is:\", var_bigram_cross_entropy, \"Perplexity is:\", var_bigram_perplexity)\n",
        "print(\"Trigram: Cross Entropy is:\", var_trigram_cross_entropy, \"Perplexity is:\", var_trigram_perplexity)\n"
      ],
      "metadata": {
        "id": "r3lz90cdBowF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf3bd934-481c-47f3-a619-8490d463e84f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigram: Cross Entropy is: 7.600183531929075 Perplexity is: 194.03640321432016\n",
            "Trigram: Cross Entropy is: 6.937863235920945 Perplexity is: 122.6040848042126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(3) Write some code to show how your bigram and trigram language models can auto-\n",
        "complete an incomplete sentenc"
      ],
      "metadata": {
        "id": "VBPKswmlDAyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"1:\", dict_bigram_probabilities[(\"county\", \"fulton\")], \"Key existing: \", (\"county\", \"fulton\") in dict_bigram_probabilities)\n",
        "# print(\"2:\", dict_bigram_probabilities[(\"fulton\", \"election\")])\n",
        "\n",
        "list_subset_complete_sentences = sent_tokenize(var_training_text)[:2]\n",
        "print(\"Sentence 1:\", list_subset_complete_sentences[0], \"Length is:\", len(list_subset_complete_sentences[0].split()))\n",
        "print(\"Sentence 2:\", list_subset_complete_sentences[1], \"Length is:\", len(list_subset_complete_sentences[1].split()))\n",
        "\n",
        "for var_sent in list_subset_complete_sentences:\n",
        "    list_incomplete_bigram_sentence = [\"<start>\"]\n",
        "    list_incomplete_trigram_sentence = [\"<start1>\", \"<start2>\"]\n",
        "    list_incomplete_bigram_sentence.extend(var_sent.split())\n",
        "    list_incomplete_trigram_sentence.extend(var_sent.split())\n",
        "    var_total_tokens = len(list_incomplete_bigram_sentence)\n",
        "    var_max_unremoved_index = var_total_tokens // 2 + 1\n",
        "    print(\"Max unremoved index is: \", var_max_unremoved_index)\n",
        "    for var_index in range(var_max_unremoved_index + 1, var_total_tokens):\n",
        "        list_incomplete_bigram_sentence.pop()\n",
        "        list_incomplete_trigram_sentence.pop()\n",
        "    print(\"Bigram Sentence Incomplete:\", list_incomplete_bigram_sentence)\n",
        "    print(\"Trigram Sentence Incomplete:\", list_incomplete_trigram_sentence)\n",
        "\n",
        "\n",
        "    for var_index in range(var_max_unremoved_index + 1, var_total_tokens):\n",
        "        var_bigram_probability = 0.0\n",
        "        var_trigram_probability = 0.0\n",
        "        tuple_bigram_choice_01 = (\" \", 0.0)\n",
        "        tuple_bigram_choice_02 = (\" \", 0.0)\n",
        "        tuple_trigram_choice_01 = (\" \", 0.0)\n",
        "        tuple_trigram_choice_02 = (\" \", 0.0)\n",
        "        #print(\"index:\", var_index, \"token:\", list_incomplete_bigram_sentence[var_index - 1])\n",
        "\n",
        "        for var_word in dict_keys_vocabulary:\n",
        "            bigram_tuple = (var_word, list_incomplete_bigram_sentence[var_index - 1])\n",
        "            var_bigram_probability = dict_bigram_probabilities.get(bigram_tuple, 1 / (dict_counter_unigrams.get(bigram_tuple[1], 0.0) + var_vocabulary_size))\n",
        "\n",
        "            trigram_tuple = (var_word, list_incomplete_trigram_sentence[var_index - 2], list_incomplete_trigram_sentence[var_index - 1])\n",
        "            var_trigram_probability = dict_trigram_probabilities.get(trigram_tuple, 1 / (dict_counter_bigrams.get((trigram_tuple[1], trigram_tuple[2]), 0.0) + var_vocabulary_size))\n",
        "\n",
        "            if  tuple_bigram_choice_01[1] < var_bigram_probability:\n",
        "                # print(\"index\", var_index, \"new candidate bigram word:\", var_word, \"tuple: \", bigram_tuple)\n",
        "                tuple_bigram_choice_02 =  tuple_bigram_choice_01\n",
        "                tuple_bigram_choice_01 = (var_word, var_bigram_probability)\n",
        "            elif tuple_bigram_choice_02[1] < var_bigram_probability:\n",
        "                tuple_bigram_choice_02 = (var_word, var_bigram_probability)\n",
        "            if tuple_trigram_choice_01[1] < var_trigram_probability:\n",
        "                # print(\"index\", var_index, \"new candidate trigram word:\", var_word, \"tuple: \", bigram_tuple)\n",
        "                tuple_trigram_choice_02 = tuple_trigram_choice_01\n",
        "                tuple_trigram_choice_01 = (var_word, var_trigram_probability)\n",
        "            elif tuple_trigram_choice_02[1] < var_trigram_probability:\n",
        "                tuple_trigram_choice_02 = (var_word, var_bigram_probability)\n",
        "        # print(\"choice_bigram_01 is:\", tuple_bigram_choice_01[0], \"choice_bigram_02 is:\", tuple_bigram_choice_02[0])\n",
        "        list_incomplete_bigram_sentence.append(tuple_bigram_choice_01[0])\n",
        "        list_incomplete_trigram_sentence.append(tuple_trigram_choice_01[0])\n",
        "    print(\"Bigram Complete:\", list_incomplete_bigram_sentence)\n",
        "    print(\"Trigram Complete:\", list_incomplete_trigram_sentence)"
      ],
      "metadata": {
        "id": "WRblu-OGByBm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79400353-a178-40c6-c2cc-2f0a964a8ac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1: fulton county grand jury said friday investigation <UNK> recent primary election <UNK> `` evidence '' <UNK> took place . Length is: 19\n",
            "Sentence 2: jury said <UNK> <UNK> city executive committee , <UNK> charge election , `` <UNK> <UNK> <UNK> city atlanta '' <UNK> election <UNK> . Length is: 23\n",
            "Max unremoved index is:  11\n",
            "Bigram Sentence Incomplete: ['<start>', 'fulton', 'county', 'grand', 'jury', 'said', 'friday', 'investigation', '<UNK>', 'recent', 'primary', 'election']\n",
            "Trigram Sentence Incomplete: ['<start1>', '<start2>', 'fulton', 'county', 'grand', 'jury', 'said', 'friday', 'investigation', '<UNK>', 'recent', 'primary', 'election']\n",
            "Bigram Complete: ['<start>', 'fulton', 'county', 'grand', 'jury', 'said', 'friday', 'investigation', '<UNK>', 'recent', 'primary', 'election', ',', 'said', '.', \"'\", \"''\", '.', \"'\", \"''\"]\n",
            "Trigram Complete: ['<start1>', '<start2>', 'fulton', 'county', 'grand', 'jury', 'said', 'friday', 'investigation', '<UNK>', 'recent', 'primary', 'election', 'election', ',', 'fulton', '``', 'tax', 'fulton', 'fulton', 'fulton']\n",
            "Max unremoved index is:  13\n",
            "Bigram Sentence Incomplete: ['<start>', 'jury', 'said', '<UNK>', '<UNK>', 'city', 'executive', 'committee', ',', '<UNK>', 'charge', 'election', ',', '``']\n",
            "Trigram Sentence Incomplete: ['<start1>', '<start2>', 'jury', 'said', '<UNK>', '<UNK>', 'city', 'executive', 'committee', ',', '<UNK>', 'charge', 'election', ',', '``']\n",
            "Bigram Complete: ['<start>', 'jury', 'said', '<UNK>', '<UNK>', 'city', 'executive', 'committee', ',', '<UNK>', 'charge', 'election', ',', '``', 'must', 'taken', 'friday', '.', \"'\", \"''\", '.', \"'\", \"''\", '.']\n",
            "Trigram Complete: ['<start1>', '<start2>', 'jury', 'said', '<UNK>', '<UNK>', 'city', 'executive', 'committee', ',', '<UNK>', 'charge', 'election', ',', '``', '``', 'feel', 'fulton', 'future', 'fulton', 'fulton', 'county', 'fulton', 'grand', 'fulton']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(4),(5),(6)\n",
        "\n",
        "Implement a context-aware Spelling corrector, generate artifical\n",
        "\n",
        "datasets for it, and evaluate it using WER and CER"
      ],
      "metadata": {
        "id": "qjAiJrK9DHSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SentenceCorrectionResult:\n",
        "    initial_sentence = \"\"\n",
        "    typos_sentence = \"\"\n",
        "    mistake_probability = 0.0\n",
        "    corrected_sentence = \"\"\n",
        "    wer = -1\n",
        "    cer = -1\n",
        "    lev_weight = -1\n",
        "    lm_weight = -1\n",
        "    def append_to_file(self,filepath):\n",
        "        with open(filepath, mode='a', encoding='utf-8') as file:\n",
        "            file.write(f\"{self.initial_sentence},{self.typos_sentence},{self.corrected_sentence},{self.mistake_probability},{self.wer},{self.cer},{self.lev_weight},{self.lm_weight}\\n\")\n",
        "\n",
        "### Context-Aware Spelling Corrector\n",
        "\n",
        "class AutoCorrector:\n",
        "    _texts = [] #= [(\"\",\"\")]\n",
        "    # this makes it so that we can use anything where we can do .get((w1,w2))\n",
        "    # to get the probability\n",
        "    _bigram_model = dict()\n",
        "    _trigram_model = dict()\n",
        "    _file_output = \"Per-Sentence-Results-Final.csv\"\n",
        "\n",
        "    _sentences_to_evaluate_on = 5\n",
        "    _mistake_probability = 0.18\n",
        "\n",
        "    _beam_search_max_depth = 7\n",
        "    _beam_search_beam_width = 4\n",
        "    _beam_search_candidates_amount = 10\n",
        "    _beam_search_use_bigram = False\n",
        "    _beam_search_weights_for_prob = (0.65, 0.35)\n",
        "\n",
        "\n",
        "    _sentences = []\n",
        "    _sentences_with_typos = []\n",
        "\n",
        "    _vocabulary = []\n",
        "    def run_with_default_settings(self,bigram_model,trigram_model,vocab):\n",
        "        self._bigram_model = bigram_model\n",
        "        self._trigram_model = trigram_model\n",
        "        self._vocabulary = vocab\n",
        "        assert (len(self._vocabulary) > 0)\n",
        "        assert (self._beam_search_candidates_amount > 0)\n",
        "\n",
        "        self.get_default_texts()\n",
        "        self.get_random_sentences_from_texts()\n",
        "        self.add_typos_to_sentences()\n",
        "        self.correct_sentences()\n",
        "\n",
        "    # (v) Create an artificial test dataset to evaluate your context-aware spelling corrector\n",
        "    def get_default_texts(self):\n",
        "        self._texts.append((europarl_raw.english.raw(),\"Sample European Parliament Proceedings Parallel Corpus\"))\n",
        "    def get_random_sentences_from_texts(self):\n",
        "        assert (len(self._texts) > 0)\n",
        "        text,title = random.choice(self._texts)\n",
        "        sentences = sent_tokenize(text)\n",
        "        random_sentences = [random.choice(sentences) for _ in range(self._sentences_to_evaluate_on)]\n",
        "        self._sentences = [s.replace(\"\\n\",\" \").replace(\",\",\" \").lower() for s in random_sentences]\n",
        "    def add_typos_to_sentences(self):\n",
        "        self._sentences_with_typos = list(map(lambda sentence: self.add_typos_to_sentence(sentence),self._sentences))\n",
        "\n",
        "    ### (VI) Evaluate your context-aware spelling corrector in terms of\n",
        "    # Word Error Rate (WER) and\n",
        "    # Character Error Rate (CER).\n",
        "    def correct_sentences(self):\n",
        "        assert (len(self._sentences) == len(self._sentences_with_typos))\n",
        "        print(\"========Correcting sentences=========\")\n",
        "        print(\"\\n\")\n",
        "        with open(self._file_output, mode=\"a\", encoding='utf-8') as file:\n",
        "            file.write(\n",
        "                \"Initial Sentence,Sentence with Typos,Corrected Sentence,Mistake Probability,WER,CER,Levenshtein Weight,Language Model Weight\\n\")\n",
        "        weight_options = [\n",
        "            #LM λ1,LEV λ2\n",
        "            (0.0, 1.0),\n",
        "            (0.1, 0.9),\n",
        "            (0.2, 0.8),\n",
        "            (0.3, 0.7),\n",
        "            (0.4, 0.6),\n",
        "            (0.5, 0.5),\n",
        "            (0.6, 0.4),\n",
        "            (0.7, 0.3),\n",
        "            (0.8, 0.2),\n",
        "            (0.9, 0.1),\n",
        "            (1.0, 0.0),\n",
        "        ]\n",
        "        for weights in weight_options:\n",
        "            self._beam_search_weights_for_prob = weights\n",
        "            avg_word_error_rate = 0\n",
        "            avg_character_error_rate = 0\n",
        "            for index in range(len(self._sentences)):\n",
        "                correct = self._sentences[index]\n",
        "                with_typos = self._sentences_with_typos[index]\n",
        "                corrected = self.correct_sentence(with_typos)\n",
        "\n",
        "                wer = AutoCorrector.WER([corrected], [correct])\n",
        "                cer = AutoCorrector.CER([corrected], [correct])\n",
        "\n",
        "                print(\"Initial Sentence->\", correct)\n",
        "                print(\"With added typos->\", with_typos)\n",
        "                print(\"Final correct sentence->\", corrected)\n",
        "                print(\"WER->\", wer)\n",
        "                print(\"CER->\", cer)\n",
        "\n",
        "                res = SentenceCorrectionResult()\n",
        "                res.initial_sentence = correct\n",
        "                res.typos_sentence = with_typos\n",
        "                res.mistake_probability = self._mistake_probability\n",
        "                res.corrected_sentence = corrected\n",
        "                res.wer = wer\n",
        "                res.cer = cer\n",
        "                res.lm_weight = self._beam_search_weights_for_prob[0]\n",
        "                res.lev_weight = self._beam_search_weights_for_prob[1]\n",
        "                res.append_to_file(self._file_output)\n",
        "\n",
        "                avg_word_error_rate = avg_word_error_rate + wer\n",
        "                avg_character_error_rate = avg_character_error_rate + cer\n",
        "            avg_word_error_rate = avg_word_error_rate / len(self._sentences)\n",
        "            avg_character_error_rate = avg_character_error_rate / len(self._sentences)\n",
        "            print(f\"For weights(lm,lev): {self._beam_search_weights_for_prob}\")\n",
        "            print(\"For mistake probability: \", self._mistake_probability)\n",
        "            print(\"Our model's AVG WER is: \", avg_word_error_rate)\n",
        "            print(\"Our model's AVG CER is: \", avg_character_error_rate)\n",
        "    def correct_sentence(self, with_typos):\n",
        "        # have not yet added <start>, <end>\n",
        "        initial_state = word_tokenize(with_typos)\n",
        "        initial_state = list(map(lambda word: word.lower(), initial_state))\n",
        "        # initial_state.insert(0,\"<start>\")\n",
        "        # initial_state.append(\"<end>\")\n",
        "        best_correction = self.beam_search_decode(\n",
        "            initial_state,\n",
        "            self._beam_search_max_depth,\n",
        "            self._beam_search_beam_width,\n",
        "            self.get_candidate_corrections_with_levenshtein,\n",
        "            self.score)\n",
        "\n",
        "        return best_correction\n",
        "\n",
        "    def add_typos_to_sentence(self,complete_text):\n",
        "        final_text = \"\"\n",
        "        def is_non_space_char(ch):\n",
        "            return ch == ' ' or ch == '\\t' or ch == '\\r' or ch == '\\n'\n",
        "        for i in range(len(complete_text)):\n",
        "            character = complete_text[i]\n",
        "            if is_non_space_char(character):\n",
        "                # so we can maintain the same sentence format\n",
        "                final_text += character\n",
        "                continue\n",
        "            p = np.random.uniform(0, 1)\n",
        "            if p <= self._mistake_probability:\n",
        "                final_text = final_text + AutoCorrector.generate_random_character(character)  # random character\n",
        "            else:\n",
        "                final_text = final_text + character\n",
        "        return final_text\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_random_character(ch):\n",
        "        # when a user does a typo he most likely was using the correct case\n",
        "        # but this is too linguistic for this case\n",
        "        if ch.islower():\n",
        "            return random.choice(string.ascii_lowercase)\n",
        "        else:\n",
        "            return random.choice(string.ascii_uppercase)\n",
        "\n",
        "\n",
        "    def get_n_closest_words(self,word,n):\n",
        "        # print(\"Word: \",word)\n",
        "        # assert(type(word) == str)\n",
        "        if word == \"?\" or word == \",\" or word == \".\":\n",
        "            return [(word,1.0) for _ in range(n)]\n",
        "\n",
        "        def edit_distance(word1):\n",
        "            return distance(word1, word)\n",
        "        closest_words = sorted(self._vocabulary, key=edit_distance)[:n]\n",
        "        # something is going wrong here\n",
        "        probs = []\n",
        "        for close_word in closest_words:\n",
        "            dist = edit_distance(close_word)\n",
        "            if dist == 0:\n",
        "                probs.append(1)\n",
        "            else:\n",
        "                probs.append(1.0/(dist + 1))\n",
        "        return list(zip(closest_words, probs))\n",
        "    def get_candidate_corrections_with_levenshtein(self, sentence_prob):\n",
        "        assert (len(sentence_prob[0]) > 0)\n",
        "        word_alternatives = []\n",
        "        for word in sentence_prob[0]:\n",
        "            if type(word) != str :continue\n",
        "            close_vocab_words = self.get_n_closest_words(word,7)\n",
        "            word_alternatives.append(close_vocab_words)\n",
        "        candidates = []\n",
        "        for i in range(self._beam_search_candidates_amount):\n",
        "            sentence = []\n",
        "            for words_to_choose_from in word_alternatives:\n",
        "                word_and_prob = max(words_to_choose_from,key=lambda x: x[1])\n",
        "                sentence.append(word_and_prob)\n",
        "            probability_of_sentence = 1\n",
        "            result = []\n",
        "            for word_prob in sentence:\n",
        "                probability_of_sentence *= word_prob[1]\n",
        "                result.append(word_prob[0])\n",
        "            candidates.append((result,probability_of_sentence))\n",
        "        return candidates\n",
        "\n",
        "\n",
        "    def score(self,state):\n",
        "        # Calculate the probability of the word sequence using the bigram model\n",
        "        # or trigram model and the levenshtein distance(of the last word of state)\n",
        "        # State-> Tuple(Sentence->Words[],Lev_Prob_Of_sentence))\n",
        "        sentence = state[0]\n",
        "        lev_probability_of_sentence = state[1]\n",
        "        lm_probability = 1.0\n",
        "        if self._beam_search_use_bigram:\n",
        "            for i in range(1, len(sentence)):\n",
        "                prev_word, word = sentence[i - 1], sentence[i]\n",
        "                lm_probability = lm_probability * self._bigram_model.get((word,prev_word), 0.0)\n",
        "        else:\n",
        "            for i in range(2, len(sentence)):\n",
        "                prev_prev_word,prev_word,word = sentence[i-2],sentence[i - 1], sentence[i]\n",
        "                lm_probability = lm_probability * self._trigram_model.get((word,prev_prev_word, prev_word), 0.0)\n",
        "        #-l1*log(P(w1|t1))-l2*log(P(t1_k))-> Slide 18 Part_01\n",
        "        result = self._beam_search_weights_for_prob[1] * log2(lev_probability_of_sentence)\n",
        "        if lm_probability != 0:\n",
        "           result += self._beam_search_weights_for_prob[0] * lm_probability\n",
        "        return -result\n",
        "\n",
        "    def is_out_of_vocabulary(self,word):\n",
        "        return not (word in self._vocabulary)\n",
        "    @staticmethod\n",
        "    def WER(predictions, references):\n",
        "        wer = load(\"wer\")\n",
        "        return wer.compute(predictions=predictions, references=references)\n",
        "    @staticmethod\n",
        "    def CER(predictions, references):\n",
        "        cer = load(\"cer\")\n",
        "        return cer.compute(predictions=predictions, references=references)\n",
        "\n",
        "    def beam_search_decode(self,initial_state, max_depth, beam_width, generate_candidates_fn, score_fn):\n",
        "        candidates = [(initial_state, 1.0)]\n",
        "        print(\"========BEAM SEARCH=======\")\n",
        "        print(\"For sentence: \",initial_state)\n",
        "        for depth in range(max_depth):\n",
        "            new_candidates = []\n",
        "            for candidate, prob in candidates:\n",
        "                for next_state in generate_candidates_fn((candidate,prob)):\n",
        "                    new_prob = prob * score_fn(next_state)\n",
        "                    new_candidates.append((next_state[0],new_prob*next_state[1]))\n",
        "\n",
        "            # print('\\n***** NEW candidates *****')\n",
        "            #print(new_candidates)\n",
        "            new_candidates = sorted(new_candidates, key=lambda x: x[1], reverse=True)\n",
        "            # print('***** Sorted')\n",
        "            #print(new_candidates)\n",
        "            #print(f'***** Chosen candidates (top-{beam_width})')\n",
        "            candidates = new_candidates[:beam_width]\n",
        "            #print(candidates)\n",
        "        assert (len(candidates) > 0)\n",
        "        best_sequence, best_prob = max(candidates, key=lambda x: x[1])\n",
        "        return \" \".join(best_sequence)\n",
        "\n",
        "\n",
        "corrector = AutoCorrector()\n",
        "corrector.run_with_default_settings(dict_bigram_probabilities,dict_trigram_probabilities,dict_keys_vocabulary)"
      ],
      "metadata": {
        "id": "gnSg1NH9B84v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5af0b85f-75c0-4ce0-f24e-a522914ae641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========Correcting sentences=========\n",
            "\n",
            "\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['xdmittedly', 'an', 'effectove', 'yompeyatioc', 'policy', 'im', 'a', 'crereqtisate', 'eor', 'rhe', 'uroper', 'operatioj', 'ol', 'jte', 'vnterfal', 'morkrt', 'and', 'of', 'economic', 'anz', 'monetary', 'ueiln', '.']\n",
            "Initial Sentence-> admittedly   an effective competition policy is a prerequisite for the proper operation of the internal market and of economic and monetary union .\n",
            "With added typos-> xdmittedly   an effectove yompeyatioc policy im a crereqtisate eor rhe uroper operatioj ol jte vnterfal morkrt and of economic anz monetary ueiln .\n",
            "Final correct sentence-> admitted an effective competition policy pm a investigate for the proper operation of joe internal market and of economic and money neil .\n",
            "WER-> 0.2608695652173913\n",
            "CER-> 0.14482758620689656\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['thg', 'eu', 'presidencj', \"'\", 's', '``', 'common', 'reaction', '``', 'against', 'ihe', 'foomatign', 'of', 'tan', 'zovernmenl', 'iv', 'austria', 'is', 'legaley', 'unjustbfbed', '.']\n",
            "Initial Sentence-> the eu presidency ' s \" common reaction \" against the formation of the government in austria is legally unjustified .\n",
            "With added typos-> thg eu presidencj ' s \" common reaction \" against ihe foomatign of tan zovernmenl iv austria is legaley unjustbfbed .\n",
            "Final correct sentence-> the eu president ' s pm common reaction pm against the formation of can government in australia is legal industries .\n",
            "WER-> 0.3333333333333333\n",
            "CER-> 0.15384615384615385\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['this', 'is', 'en', 'admzysion', 'that', 'csnfirss', 'all', 'obr', 'romcerpb', 'and', 'manes', 'parliamevt', \"'\", 's', 'pysitiom', 'on', 'shg', 'case', 'alf', 'the', 'mare', 'appqopriati', 'as', 'it', 'tally', 'for', 'a', 'concurrenz', 'ueplanation', 'of', 'other', 'fases', 'of', 'jguinhlisrs', 'whk', 'ivne', 'disappeared', 'in', 'the', 'cqechen', 'region', 'dufing', 'the', 'conflict', 'and', 'the', 'sapeguarding', 'lf', 'msdie', 'covebage', 'of', 'f', 'conflict', 'thdi', 'has', 'reafhed', 'jnacceptable', 'oevems', 'of', 'vijlence', '.']\n",
            "Initial Sentence-> this is an admission that confirms all our concerns and makes parliament ' s position on the case all the more appropriate   as it calls for a concurrent explanation of other cases of journalists who have disappeared in the chechen region during the conflict and the safeguarding of media coverage of a conflict that has reached unacceptable levels of violence .\n",
            "With added typos-> this is en admzysion that csnfirss all obr romcerpb and manes parliamevt ' s pysitiom on shg case alf the mare appqopriati   as it tally for a concurrenz ueplanation of other fases of jguinhlisrs whk ivne disappeared in the cqechen region dufing the conflict and the sapeguarding lf msdie covebage of f conflict thdi has reafhed jnacceptable oevems of vijlence .\n",
            "Final correct sentence-> this is on division that confirms all or roberts and mines parliament ' s position on she case all the mark appropriate as it tall for a concern explanation of other cases of guidelines who in disappeared in the chicken region during the conflict and the regarding of made coverage of of conflict the has reached unacceptable levels of violence .\n",
            "WER-> 0.26229508196721313\n",
            "CER-> 0.125\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['aow', 'will', 'the', 'commissizn', 'ts', 'keeper', 'of', 'the', 'taeabies', 'gundanmek', 'uhat', 'deciqions', 'are', 'taken', 'uaqforwly', 'in', 'matkers', 'of', 'cempotition', 'in', 'londoq', 'jalermo', 'helsinki', 'and', 'soox', 'budapest', 'mnd', 'ankayt', '?']\n",
            "Initial Sentence-> how will the commission   as keeper of the treaties   guarantee that decisions are taken uniformly in matters of competition in london   palermo   helsinki and   soon   budapest and ankara ?\n",
            "With added typos-> aow will the commissizn   ts keeper of the taeabies   gundanmek uhat deciqions are taken uaqforwly in matkers of cempotition in londoq   jalermo   helsinki and   soox   budapest mnd ankayt ?\n",
            "Final correct sentence-> now will the commission to deeper of the theories guarantee that decisions are taken fairly in makers of competition in london alert helping and soon budget and analyst ?\n",
            "WER-> 0.3448275862068966\n",
            "CER-> 0.15730337078651685\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['thu', 'prhncitle', 'of', 'compltition', 'must', 'qok', 'qe', 'universkl', 'un', 'its', 'applicvtion', '.']\n",
            "Initial Sentence-> the principle of competition must now be universal in its application .\n",
            "With added typos-> thu prhncitle of compltition must qok qe universkl un its applicvtion .\n",
            "Final correct sentence-> the principle of competition must of he universal un its application .\n",
            "WER-> 0.25\n",
            "CER-> 0.056338028169014086\n",
            "For weights(lm,lev): (0.0, 1.0)\n",
            "For mistake probability:  0.18\n",
            "Our model's AVG WER is:  0.29026511334496685\n",
            "Our model's AVG CER is:  0.12746302780171628\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['xdmittedly', 'an', 'effectove', 'yompeyatioc', 'policy', 'im', 'a', 'crereqtisate', 'eor', 'rhe', 'uroper', 'operatioj', 'ol', 'jte', 'vnterfal', 'morkrt', 'and', 'of', 'economic', 'anz', 'monetary', 'ueiln', '.']\n",
            "Initial Sentence-> admittedly   an effective competition policy is a prerequisite for the proper operation of the internal market and of economic and monetary union .\n",
            "With added typos-> xdmittedly   an effectove yompeyatioc policy im a crereqtisate eor rhe uroper operatioj ol jte vnterfal morkrt and of economic anz monetary ueiln .\n",
            "Final correct sentence-> admitted an effective competition policy pm a investigate for the proper operation of joe internal market and of economic and money neil .\n",
            "WER-> 0.2608695652173913\n",
            "CER-> 0.14482758620689656\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['thg', 'eu', 'presidencj', \"'\", 's', '``', 'common', 'reaction', '``', 'against', 'ihe', 'foomatign', 'of', 'tan', 'zovernmenl', 'iv', 'austria', 'is', 'legaley', 'unjustbfbed', '.']\n",
            "Initial Sentence-> the eu presidency ' s \" common reaction \" against the formation of the government in austria is legally unjustified .\n",
            "With added typos-> thg eu presidencj ' s \" common reaction \" against ihe foomatign of tan zovernmenl iv austria is legaley unjustbfbed .\n",
            "Final correct sentence-> the eu president ' s pm common reaction pm against the formation of can government in australia is legal industries .\n",
            "WER-> 0.3333333333333333\n",
            "CER-> 0.15384615384615385\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['this', 'is', 'en', 'admzysion', 'that', 'csnfirss', 'all', 'obr', 'romcerpb', 'and', 'manes', 'parliamevt', \"'\", 's', 'pysitiom', 'on', 'shg', 'case', 'alf', 'the', 'mare', 'appqopriati', 'as', 'it', 'tally', 'for', 'a', 'concurrenz', 'ueplanation', 'of', 'other', 'fases', 'of', 'jguinhlisrs', 'whk', 'ivne', 'disappeared', 'in', 'the', 'cqechen', 'region', 'dufing', 'the', 'conflict', 'and', 'the', 'sapeguarding', 'lf', 'msdie', 'covebage', 'of', 'f', 'conflict', 'thdi', 'has', 'reafhed', 'jnacceptable', 'oevems', 'of', 'vijlence', '.']\n",
            "Initial Sentence-> this is an admission that confirms all our concerns and makes parliament ' s position on the case all the more appropriate   as it calls for a concurrent explanation of other cases of journalists who have disappeared in the chechen region during the conflict and the safeguarding of media coverage of a conflict that has reached unacceptable levels of violence .\n",
            "With added typos-> this is en admzysion that csnfirss all obr romcerpb and manes parliamevt ' s pysitiom on shg case alf the mare appqopriati   as it tally for a concurrenz ueplanation of other fases of jguinhlisrs whk ivne disappeared in the cqechen region dufing the conflict and the sapeguarding lf msdie covebage of f conflict thdi has reafhed jnacceptable oevems of vijlence .\n",
            "Final correct sentence-> this is on division that confirms all or roberts and mines parliament ' s position on she case all the mark appropriate as it tall for a concern explanation of other cases of guidelines who in disappeared in the chicken region during the conflict and the regarding of made coverage of of conflict the has reached unacceptable levels of violence .\n",
            "WER-> 0.26229508196721313\n",
            "CER-> 0.125\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['aow', 'will', 'the', 'commissizn', 'ts', 'keeper', 'of', 'the', 'taeabies', 'gundanmek', 'uhat', 'deciqions', 'are', 'taken', 'uaqforwly', 'in', 'matkers', 'of', 'cempotition', 'in', 'londoq', 'jalermo', 'helsinki', 'and', 'soox', 'budapest', 'mnd', 'ankayt', '?']\n",
            "Initial Sentence-> how will the commission   as keeper of the treaties   guarantee that decisions are taken uniformly in matters of competition in london   palermo   helsinki and   soon   budapest and ankara ?\n",
            "With added typos-> aow will the commissizn   ts keeper of the taeabies   gundanmek uhat deciqions are taken uaqforwly in matkers of cempotition in londoq   jalermo   helsinki and   soox   budapest mnd ankayt ?\n",
            "Final correct sentence-> now will the commission to deeper of the theories guarantee that decisions are taken fairly in makers of competition in london alert helping and soon budget and analyst ?\n",
            "WER-> 0.3448275862068966\n",
            "CER-> 0.15730337078651685\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['thu', 'prhncitle', 'of', 'compltition', 'must', 'qok', 'qe', 'universkl', 'un', 'its', 'applicvtion', '.']\n",
            "Initial Sentence-> the principle of competition must now be universal in its application .\n",
            "With added typos-> thu prhncitle of compltition must qok qe universkl un its applicvtion .\n",
            "Final correct sentence-> the principle of competition must of he universal un its application .\n",
            "WER-> 0.25\n",
            "CER-> 0.056338028169014086\n",
            "For weights(lm,lev): (0.1, 0.9)\n",
            "For mistake probability:  0.18\n",
            "Our model's AVG WER is:  0.29026511334496685\n",
            "Our model's AVG CER is:  0.12746302780171628\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['xdmittedly', 'an', 'effectove', 'yompeyatioc', 'policy', 'im', 'a', 'crereqtisate', 'eor', 'rhe', 'uroper', 'operatioj', 'ol', 'jte', 'vnterfal', 'morkrt', 'and', 'of', 'economic', 'anz', 'monetary', 'ueiln', '.']\n",
            "Initial Sentence-> admittedly   an effective competition policy is a prerequisite for the proper operation of the internal market and of economic and monetary union .\n",
            "With added typos-> xdmittedly   an effectove yompeyatioc policy im a crereqtisate eor rhe uroper operatioj ol jte vnterfal morkrt and of economic anz monetary ueiln .\n",
            "Final correct sentence-> admitted an effective competition policy pm a investigate for the proper operation of joe internal market and of economic and money neil .\n",
            "WER-> 0.2608695652173913\n",
            "CER-> 0.14482758620689656\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['thg', 'eu', 'presidencj', \"'\", 's', '``', 'common', 'reaction', '``', 'against', 'ihe', 'foomatign', 'of', 'tan', 'zovernmenl', 'iv', 'austria', 'is', 'legaley', 'unjustbfbed', '.']\n",
            "Initial Sentence-> the eu presidency ' s \" common reaction \" against the formation of the government in austria is legally unjustified .\n",
            "With added typos-> thg eu presidencj ' s \" common reaction \" against ihe foomatign of tan zovernmenl iv austria is legaley unjustbfbed .\n",
            "Final correct sentence-> the eu president ' s pm common reaction pm against the formation of can government in australia is legal industries .\n",
            "WER-> 0.3333333333333333\n",
            "CER-> 0.15384615384615385\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['this', 'is', 'en', 'admzysion', 'that', 'csnfirss', 'all', 'obr', 'romcerpb', 'and', 'manes', 'parliamevt', \"'\", 's', 'pysitiom', 'on', 'shg', 'case', 'alf', 'the', 'mare', 'appqopriati', 'as', 'it', 'tally', 'for', 'a', 'concurrenz', 'ueplanation', 'of', 'other', 'fases', 'of', 'jguinhlisrs', 'whk', 'ivne', 'disappeared', 'in', 'the', 'cqechen', 'region', 'dufing', 'the', 'conflict', 'and', 'the', 'sapeguarding', 'lf', 'msdie', 'covebage', 'of', 'f', 'conflict', 'thdi', 'has', 'reafhed', 'jnacceptable', 'oevems', 'of', 'vijlence', '.']\n",
            "Initial Sentence-> this is an admission that confirms all our concerns and makes parliament ' s position on the case all the more appropriate   as it calls for a concurrent explanation of other cases of journalists who have disappeared in the chechen region during the conflict and the safeguarding of media coverage of a conflict that has reached unacceptable levels of violence .\n",
            "With added typos-> this is en admzysion that csnfirss all obr romcerpb and manes parliamevt ' s pysitiom on shg case alf the mare appqopriati   as it tally for a concurrenz ueplanation of other fases of jguinhlisrs whk ivne disappeared in the cqechen region dufing the conflict and the sapeguarding lf msdie covebage of f conflict thdi has reafhed jnacceptable oevems of vijlence .\n",
            "Final correct sentence-> this is on division that confirms all or roberts and mines parliament ' s position on she case all the mark appropriate as it tall for a concern explanation of other cases of guidelines who in disappeared in the chicken region during the conflict and the regarding of made coverage of of conflict the has reached unacceptable levels of violence .\n",
            "WER-> 0.26229508196721313\n",
            "CER-> 0.125\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['aow', 'will', 'the', 'commissizn', 'ts', 'keeper', 'of', 'the', 'taeabies', 'gundanmek', 'uhat', 'deciqions', 'are', 'taken', 'uaqforwly', 'in', 'matkers', 'of', 'cempotition', 'in', 'londoq', 'jalermo', 'helsinki', 'and', 'soox', 'budapest', 'mnd', 'ankayt', '?']\n",
            "Initial Sentence-> how will the commission   as keeper of the treaties   guarantee that decisions are taken uniformly in matters of competition in london   palermo   helsinki and   soon   budapest and ankara ?\n",
            "With added typos-> aow will the commissizn   ts keeper of the taeabies   gundanmek uhat deciqions are taken uaqforwly in matkers of cempotition in londoq   jalermo   helsinki and   soox   budapest mnd ankayt ?\n",
            "Final correct sentence-> now will the commission to deeper of the theories guarantee that decisions are taken fairly in makers of competition in london alert helping and soon budget and analyst ?\n",
            "WER-> 0.3448275862068966\n",
            "CER-> 0.15730337078651685\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['thu', 'prhncitle', 'of', 'compltition', 'must', 'qok', 'qe', 'universkl', 'un', 'its', 'applicvtion', '.']\n",
            "Initial Sentence-> the principle of competition must now be universal in its application .\n",
            "With added typos-> thu prhncitle of compltition must qok qe universkl un its applicvtion .\n",
            "Final correct sentence-> the principle of competition must of he universal un its application .\n",
            "WER-> 0.25\n",
            "CER-> 0.056338028169014086\n",
            "For weights(lm,lev): (0.2, 0.8)\n",
            "For mistake probability:  0.18\n",
            "Our model's AVG WER is:  0.29026511334496685\n",
            "Our model's AVG CER is:  0.12746302780171628\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['xdmittedly', 'an', 'effectove', 'yompeyatioc', 'policy', 'im', 'a', 'crereqtisate', 'eor', 'rhe', 'uroper', 'operatioj', 'ol', 'jte', 'vnterfal', 'morkrt', 'and', 'of', 'economic', 'anz', 'monetary', 'ueiln', '.']\n",
            "Initial Sentence-> admittedly   an effective competition policy is a prerequisite for the proper operation of the internal market and of economic and monetary union .\n",
            "With added typos-> xdmittedly   an effectove yompeyatioc policy im a crereqtisate eor rhe uroper operatioj ol jte vnterfal morkrt and of economic anz monetary ueiln .\n",
            "Final correct sentence-> admitted an effective competition policy pm a investigate for the proper operation of joe internal market and of economic and money neil .\n",
            "WER-> 0.2608695652173913\n",
            "CER-> 0.14482758620689656\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['thg', 'eu', 'presidencj', \"'\", 's', '``', 'common', 'reaction', '``', 'against', 'ihe', 'foomatign', 'of', 'tan', 'zovernmenl', 'iv', 'austria', 'is', 'legaley', 'unjustbfbed', '.']\n",
            "Initial Sentence-> the eu presidency ' s \" common reaction \" against the formation of the government in austria is legally unjustified .\n",
            "With added typos-> thg eu presidencj ' s \" common reaction \" against ihe foomatign of tan zovernmenl iv austria is legaley unjustbfbed .\n",
            "Final correct sentence-> the eu president ' s pm common reaction pm against the formation of can government in australia is legal industries .\n",
            "WER-> 0.3333333333333333\n",
            "CER-> 0.15384615384615385\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['this', 'is', 'en', 'admzysion', 'that', 'csnfirss', 'all', 'obr', 'romcerpb', 'and', 'manes', 'parliamevt', \"'\", 's', 'pysitiom', 'on', 'shg', 'case', 'alf', 'the', 'mare', 'appqopriati', 'as', 'it', 'tally', 'for', 'a', 'concurrenz', 'ueplanation', 'of', 'other', 'fases', 'of', 'jguinhlisrs', 'whk', 'ivne', 'disappeared', 'in', 'the', 'cqechen', 'region', 'dufing', 'the', 'conflict', 'and', 'the', 'sapeguarding', 'lf', 'msdie', 'covebage', 'of', 'f', 'conflict', 'thdi', 'has', 'reafhed', 'jnacceptable', 'oevems', 'of', 'vijlence', '.']\n",
            "Initial Sentence-> this is an admission that confirms all our concerns and makes parliament ' s position on the case all the more appropriate   as it calls for a concurrent explanation of other cases of journalists who have disappeared in the chechen region during the conflict and the safeguarding of media coverage of a conflict that has reached unacceptable levels of violence .\n",
            "With added typos-> this is en admzysion that csnfirss all obr romcerpb and manes parliamevt ' s pysitiom on shg case alf the mare appqopriati   as it tally for a concurrenz ueplanation of other fases of jguinhlisrs whk ivne disappeared in the cqechen region dufing the conflict and the sapeguarding lf msdie covebage of f conflict thdi has reafhed jnacceptable oevems of vijlence .\n",
            "Final correct sentence-> this is on division that confirms all or roberts and mines parliament ' s position on she case all the mark appropriate as it tall for a concern explanation of other cases of guidelines who in disappeared in the chicken region during the conflict and the regarding of made coverage of of conflict the has reached unacceptable levels of violence .\n",
            "WER-> 0.26229508196721313\n",
            "CER-> 0.125\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['aow', 'will', 'the', 'commissizn', 'ts', 'keeper', 'of', 'the', 'taeabies', 'gundanmek', 'uhat', 'deciqions', 'are', 'taken', 'uaqforwly', 'in', 'matkers', 'of', 'cempotition', 'in', 'londoq', 'jalermo', 'helsinki', 'and', 'soox', 'budapest', 'mnd', 'ankayt', '?']\n",
            "Initial Sentence-> how will the commission   as keeper of the treaties   guarantee that decisions are taken uniformly in matters of competition in london   palermo   helsinki and   soon   budapest and ankara ?\n",
            "With added typos-> aow will the commissizn   ts keeper of the taeabies   gundanmek uhat deciqions are taken uaqforwly in matkers of cempotition in londoq   jalermo   helsinki and   soox   budapest mnd ankayt ?\n",
            "Final correct sentence-> now will the commission to deeper of the theories guarantee that decisions are taken fairly in makers of competition in london alert helping and soon budget and analyst ?\n",
            "WER-> 0.3448275862068966\n",
            "CER-> 0.15730337078651685\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['thu', 'prhncitle', 'of', 'compltition', 'must', 'qok', 'qe', 'universkl', 'un', 'its', 'applicvtion', '.']\n",
            "Initial Sentence-> the principle of competition must now be universal in its application .\n",
            "With added typos-> thu prhncitle of compltition must qok qe universkl un its applicvtion .\n",
            "Final correct sentence-> the principle of competition must of he universal un its application .\n",
            "WER-> 0.25\n",
            "CER-> 0.056338028169014086\n",
            "For weights(lm,lev): (0.3, 0.7)\n",
            "For mistake probability:  0.18\n",
            "Our model's AVG WER is:  0.29026511334496685\n",
            "Our model's AVG CER is:  0.12746302780171628\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['xdmittedly', 'an', 'effectove', 'yompeyatioc', 'policy', 'im', 'a', 'crereqtisate', 'eor', 'rhe', 'uroper', 'operatioj', 'ol', 'jte', 'vnterfal', 'morkrt', 'and', 'of', 'economic', 'anz', 'monetary', 'ueiln', '.']\n",
            "Initial Sentence-> admittedly   an effective competition policy is a prerequisite for the proper operation of the internal market and of economic and monetary union .\n",
            "With added typos-> xdmittedly   an effectove yompeyatioc policy im a crereqtisate eor rhe uroper operatioj ol jte vnterfal morkrt and of economic anz monetary ueiln .\n",
            "Final correct sentence-> admitted an effective competition policy pm a investigate for the proper operation of joe internal market and of economic and money neil .\n",
            "WER-> 0.2608695652173913\n",
            "CER-> 0.14482758620689656\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['thg', 'eu', 'presidencj', \"'\", 's', '``', 'common', 'reaction', '``', 'against', 'ihe', 'foomatign', 'of', 'tan', 'zovernmenl', 'iv', 'austria', 'is', 'legaley', 'unjustbfbed', '.']\n",
            "Initial Sentence-> the eu presidency ' s \" common reaction \" against the formation of the government in austria is legally unjustified .\n",
            "With added typos-> thg eu presidencj ' s \" common reaction \" against ihe foomatign of tan zovernmenl iv austria is legaley unjustbfbed .\n",
            "Final correct sentence-> the eu president ' s pm common reaction pm against the formation of can government in australia is legal industries .\n",
            "WER-> 0.3333333333333333\n",
            "CER-> 0.15384615384615385\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['this', 'is', 'en', 'admzysion', 'that', 'csnfirss', 'all', 'obr', 'romcerpb', 'and', 'manes', 'parliamevt', \"'\", 's', 'pysitiom', 'on', 'shg', 'case', 'alf', 'the', 'mare', 'appqopriati', 'as', 'it', 'tally', 'for', 'a', 'concurrenz', 'ueplanation', 'of', 'other', 'fases', 'of', 'jguinhlisrs', 'whk', 'ivne', 'disappeared', 'in', 'the', 'cqechen', 'region', 'dufing', 'the', 'conflict', 'and', 'the', 'sapeguarding', 'lf', 'msdie', 'covebage', 'of', 'f', 'conflict', 'thdi', 'has', 'reafhed', 'jnacceptable', 'oevems', 'of', 'vijlence', '.']\n",
            "Initial Sentence-> this is an admission that confirms all our concerns and makes parliament ' s position on the case all the more appropriate   as it calls for a concurrent explanation of other cases of journalists who have disappeared in the chechen region during the conflict and the safeguarding of media coverage of a conflict that has reached unacceptable levels of violence .\n",
            "With added typos-> this is en admzysion that csnfirss all obr romcerpb and manes parliamevt ' s pysitiom on shg case alf the mare appqopriati   as it tally for a concurrenz ueplanation of other fases of jguinhlisrs whk ivne disappeared in the cqechen region dufing the conflict and the sapeguarding lf msdie covebage of f conflict thdi has reafhed jnacceptable oevems of vijlence .\n",
            "Final correct sentence-> this is on division that confirms all or roberts and mines parliament ' s position on she case all the mark appropriate as it tall for a concern explanation of other cases of guidelines who in disappeared in the chicken region during the conflict and the regarding of made coverage of of conflict the has reached unacceptable levels of violence .\n",
            "WER-> 0.26229508196721313\n",
            "CER-> 0.125\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['aow', 'will', 'the', 'commissizn', 'ts', 'keeper', 'of', 'the', 'taeabies', 'gundanmek', 'uhat', 'deciqions', 'are', 'taken', 'uaqforwly', 'in', 'matkers', 'of', 'cempotition', 'in', 'londoq', 'jalermo', 'helsinki', 'and', 'soox', 'budapest', 'mnd', 'ankayt', '?']\n",
            "Initial Sentence-> how will the commission   as keeper of the treaties   guarantee that decisions are taken uniformly in matters of competition in london   palermo   helsinki and   soon   budapest and ankara ?\n",
            "With added typos-> aow will the commissizn   ts keeper of the taeabies   gundanmek uhat deciqions are taken uaqforwly in matkers of cempotition in londoq   jalermo   helsinki and   soox   budapest mnd ankayt ?\n",
            "Final correct sentence-> now will the commission to deeper of the theories guarantee that decisions are taken fairly in makers of competition in london alert helping and soon budget and analyst ?\n",
            "WER-> 0.3448275862068966\n",
            "CER-> 0.15730337078651685\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['thu', 'prhncitle', 'of', 'compltition', 'must', 'qok', 'qe', 'universkl', 'un', 'its', 'applicvtion', '.']\n",
            "Initial Sentence-> the principle of competition must now be universal in its application .\n",
            "With added typos-> thu prhncitle of compltition must qok qe universkl un its applicvtion .\n",
            "Final correct sentence-> the principle of competition must of he universal un its application .\n",
            "WER-> 0.25\n",
            "CER-> 0.056338028169014086\n",
            "For weights(lm,lev): (0.4, 0.6)\n",
            "For mistake probability:  0.18\n",
            "Our model's AVG WER is:  0.29026511334496685\n",
            "Our model's AVG CER is:  0.12746302780171628\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['xdmittedly', 'an', 'effectove', 'yompeyatioc', 'policy', 'im', 'a', 'crereqtisate', 'eor', 'rhe', 'uroper', 'operatioj', 'ol', 'jte', 'vnterfal', 'morkrt', 'and', 'of', 'economic', 'anz', 'monetary', 'ueiln', '.']\n",
            "Initial Sentence-> admittedly   an effective competition policy is a prerequisite for the proper operation of the internal market and of economic and monetary union .\n",
            "With added typos-> xdmittedly   an effectove yompeyatioc policy im a crereqtisate eor rhe uroper operatioj ol jte vnterfal morkrt and of economic anz monetary ueiln .\n",
            "Final correct sentence-> admitted an effective competition policy pm a investigate for the proper operation of joe internal market and of economic and money neil .\n",
            "WER-> 0.2608695652173913\n",
            "CER-> 0.14482758620689656\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['thg', 'eu', 'presidencj', \"'\", 's', '``', 'common', 'reaction', '``', 'against', 'ihe', 'foomatign', 'of', 'tan', 'zovernmenl', 'iv', 'austria', 'is', 'legaley', 'unjustbfbed', '.']\n",
            "Initial Sentence-> the eu presidency ' s \" common reaction \" against the formation of the government in austria is legally unjustified .\n",
            "With added typos-> thg eu presidencj ' s \" common reaction \" against ihe foomatign of tan zovernmenl iv austria is legaley unjustbfbed .\n",
            "Final correct sentence-> the eu president ' s pm common reaction pm against the formation of can government in australia is legal industries .\n",
            "WER-> 0.3333333333333333\n",
            "CER-> 0.15384615384615385\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['this', 'is', 'en', 'admzysion', 'that', 'csnfirss', 'all', 'obr', 'romcerpb', 'and', 'manes', 'parliamevt', \"'\", 's', 'pysitiom', 'on', 'shg', 'case', 'alf', 'the', 'mare', 'appqopriati', 'as', 'it', 'tally', 'for', 'a', 'concurrenz', 'ueplanation', 'of', 'other', 'fases', 'of', 'jguinhlisrs', 'whk', 'ivne', 'disappeared', 'in', 'the', 'cqechen', 'region', 'dufing', 'the', 'conflict', 'and', 'the', 'sapeguarding', 'lf', 'msdie', 'covebage', 'of', 'f', 'conflict', 'thdi', 'has', 'reafhed', 'jnacceptable', 'oevems', 'of', 'vijlence', '.']\n",
            "Initial Sentence-> this is an admission that confirms all our concerns and makes parliament ' s position on the case all the more appropriate   as it calls for a concurrent explanation of other cases of journalists who have disappeared in the chechen region during the conflict and the safeguarding of media coverage of a conflict that has reached unacceptable levels of violence .\n",
            "With added typos-> this is en admzysion that csnfirss all obr romcerpb and manes parliamevt ' s pysitiom on shg case alf the mare appqopriati   as it tally for a concurrenz ueplanation of other fases of jguinhlisrs whk ivne disappeared in the cqechen region dufing the conflict and the sapeguarding lf msdie covebage of f conflict thdi has reafhed jnacceptable oevems of vijlence .\n",
            "Final correct sentence-> this is on division that confirms all or roberts and mines parliament ' s position on she case all the mark appropriate as it tall for a concern explanation of other cases of guidelines who in disappeared in the chicken region during the conflict and the regarding of made coverage of of conflict the has reached unacceptable levels of violence .\n",
            "WER-> 0.26229508196721313\n",
            "CER-> 0.125\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['aow', 'will', 'the', 'commissizn', 'ts', 'keeper', 'of', 'the', 'taeabies', 'gundanmek', 'uhat', 'deciqions', 'are', 'taken', 'uaqforwly', 'in', 'matkers', 'of', 'cempotition', 'in', 'londoq', 'jalermo', 'helsinki', 'and', 'soox', 'budapest', 'mnd', 'ankayt', '?']\n",
            "Initial Sentence-> how will the commission   as keeper of the treaties   guarantee that decisions are taken uniformly in matters of competition in london   palermo   helsinki and   soon   budapest and ankara ?\n",
            "With added typos-> aow will the commissizn   ts keeper of the taeabies   gundanmek uhat deciqions are taken uaqforwly in matkers of cempotition in londoq   jalermo   helsinki and   soox   budapest mnd ankayt ?\n",
            "Final correct sentence-> now will the commission to deeper of the theories guarantee that decisions are taken fairly in makers of competition in london alert helping and soon budget and analyst ?\n",
            "WER-> 0.3448275862068966\n",
            "CER-> 0.15730337078651685\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['thu', 'prhncitle', 'of', 'compltition', 'must', 'qok', 'qe', 'universkl', 'un', 'its', 'applicvtion', '.']\n",
            "Initial Sentence-> the principle of competition must now be universal in its application .\n",
            "With added typos-> thu prhncitle of compltition must qok qe universkl un its applicvtion .\n",
            "Final correct sentence-> the principle of competition must of he universal un its application .\n",
            "WER-> 0.25\n",
            "CER-> 0.056338028169014086\n",
            "For weights(lm,lev): (0.5, 0.5)\n",
            "For mistake probability:  0.18\n",
            "Our model's AVG WER is:  0.29026511334496685\n",
            "Our model's AVG CER is:  0.12746302780171628\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['xdmittedly', 'an', 'effectove', 'yompeyatioc', 'policy', 'im', 'a', 'crereqtisate', 'eor', 'rhe', 'uroper', 'operatioj', 'ol', 'jte', 'vnterfal', 'morkrt', 'and', 'of', 'economic', 'anz', 'monetary', 'ueiln', '.']\n",
            "Initial Sentence-> admittedly   an effective competition policy is a prerequisite for the proper operation of the internal market and of economic and monetary union .\n",
            "With added typos-> xdmittedly   an effectove yompeyatioc policy im a crereqtisate eor rhe uroper operatioj ol jte vnterfal morkrt and of economic anz monetary ueiln .\n",
            "Final correct sentence-> admitted an effective competition policy pm a investigate for the proper operation of joe internal market and of economic and money neil .\n",
            "WER-> 0.2608695652173913\n",
            "CER-> 0.14482758620689656\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['thg', 'eu', 'presidencj', \"'\", 's', '``', 'common', 'reaction', '``', 'against', 'ihe', 'foomatign', 'of', 'tan', 'zovernmenl', 'iv', 'austria', 'is', 'legaley', 'unjustbfbed', '.']\n",
            "Initial Sentence-> the eu presidency ' s \" common reaction \" against the formation of the government in austria is legally unjustified .\n",
            "With added typos-> thg eu presidencj ' s \" common reaction \" against ihe foomatign of tan zovernmenl iv austria is legaley unjustbfbed .\n",
            "Final correct sentence-> the eu president ' s pm common reaction pm against the formation of can government in australia is legal industries .\n",
            "WER-> 0.3333333333333333\n",
            "CER-> 0.15384615384615385\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['this', 'is', 'en', 'admzysion', 'that', 'csnfirss', 'all', 'obr', 'romcerpb', 'and', 'manes', 'parliamevt', \"'\", 's', 'pysitiom', 'on', 'shg', 'case', 'alf', 'the', 'mare', 'appqopriati', 'as', 'it', 'tally', 'for', 'a', 'concurrenz', 'ueplanation', 'of', 'other', 'fases', 'of', 'jguinhlisrs', 'whk', 'ivne', 'disappeared', 'in', 'the', 'cqechen', 'region', 'dufing', 'the', 'conflict', 'and', 'the', 'sapeguarding', 'lf', 'msdie', 'covebage', 'of', 'f', 'conflict', 'thdi', 'has', 'reafhed', 'jnacceptable', 'oevems', 'of', 'vijlence', '.']\n",
            "Initial Sentence-> this is an admission that confirms all our concerns and makes parliament ' s position on the case all the more appropriate   as it calls for a concurrent explanation of other cases of journalists who have disappeared in the chechen region during the conflict and the safeguarding of media coverage of a conflict that has reached unacceptable levels of violence .\n",
            "With added typos-> this is en admzysion that csnfirss all obr romcerpb and manes parliamevt ' s pysitiom on shg case alf the mare appqopriati   as it tally for a concurrenz ueplanation of other fases of jguinhlisrs whk ivne disappeared in the cqechen region dufing the conflict and the sapeguarding lf msdie covebage of f conflict thdi has reafhed jnacceptable oevems of vijlence .\n",
            "Final correct sentence-> this is on division that confirms all or roberts and mines parliament ' s position on she case all the mark appropriate as it tall for a concern explanation of other cases of guidelines who in disappeared in the chicken region during the conflict and the regarding of made coverage of of conflict the has reached unacceptable levels of violence .\n",
            "WER-> 0.26229508196721313\n",
            "CER-> 0.125\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['aow', 'will', 'the', 'commissizn', 'ts', 'keeper', 'of', 'the', 'taeabies', 'gundanmek', 'uhat', 'deciqions', 'are', 'taken', 'uaqforwly', 'in', 'matkers', 'of', 'cempotition', 'in', 'londoq', 'jalermo', 'helsinki', 'and', 'soox', 'budapest', 'mnd', 'ankayt', '?']\n",
            "Initial Sentence-> how will the commission   as keeper of the treaties   guarantee that decisions are taken uniformly in matters of competition in london   palermo   helsinki and   soon   budapest and ankara ?\n",
            "With added typos-> aow will the commissizn   ts keeper of the taeabies   gundanmek uhat deciqions are taken uaqforwly in matkers of cempotition in londoq   jalermo   helsinki and   soox   budapest mnd ankayt ?\n",
            "Final correct sentence-> now will the commission to deeper of the theories guarantee that decisions are taken fairly in makers of competition in london alert helping and soon budget and analyst ?\n",
            "WER-> 0.3448275862068966\n",
            "CER-> 0.15730337078651685\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['thu', 'prhncitle', 'of', 'compltition', 'must', 'qok', 'qe', 'universkl', 'un', 'its', 'applicvtion', '.']\n",
            "Initial Sentence-> the principle of competition must now be universal in its application .\n",
            "With added typos-> thu prhncitle of compltition must qok qe universkl un its applicvtion .\n",
            "Final correct sentence-> the principle of competition must of he universal un its application .\n",
            "WER-> 0.25\n",
            "CER-> 0.056338028169014086\n",
            "For weights(lm,lev): (0.6, 0.4)\n",
            "For mistake probability:  0.18\n",
            "Our model's AVG WER is:  0.29026511334496685\n",
            "Our model's AVG CER is:  0.12746302780171628\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['xdmittedly', 'an', 'effectove', 'yompeyatioc', 'policy', 'im', 'a', 'crereqtisate', 'eor', 'rhe', 'uroper', 'operatioj', 'ol', 'jte', 'vnterfal', 'morkrt', 'and', 'of', 'economic', 'anz', 'monetary', 'ueiln', '.']\n",
            "Initial Sentence-> admittedly   an effective competition policy is a prerequisite for the proper operation of the internal market and of economic and monetary union .\n",
            "With added typos-> xdmittedly   an effectove yompeyatioc policy im a crereqtisate eor rhe uroper operatioj ol jte vnterfal morkrt and of economic anz monetary ueiln .\n",
            "Final correct sentence-> admitted an effective competition policy pm a investigate for the proper operation of joe internal market and of economic and money neil .\n",
            "WER-> 0.2608695652173913\n",
            "CER-> 0.14482758620689656\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['thg', 'eu', 'presidencj', \"'\", 's', '``', 'common', 'reaction', '``', 'against', 'ihe', 'foomatign', 'of', 'tan', 'zovernmenl', 'iv', 'austria', 'is', 'legaley', 'unjustbfbed', '.']\n",
            "Initial Sentence-> the eu presidency ' s \" common reaction \" against the formation of the government in austria is legally unjustified .\n",
            "With added typos-> thg eu presidencj ' s \" common reaction \" against ihe foomatign of tan zovernmenl iv austria is legaley unjustbfbed .\n",
            "Final correct sentence-> the eu president ' s pm common reaction pm against the formation of can government in australia is legal industries .\n",
            "WER-> 0.3333333333333333\n",
            "CER-> 0.15384615384615385\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['this', 'is', 'en', 'admzysion', 'that', 'csnfirss', 'all', 'obr', 'romcerpb', 'and', 'manes', 'parliamevt', \"'\", 's', 'pysitiom', 'on', 'shg', 'case', 'alf', 'the', 'mare', 'appqopriati', 'as', 'it', 'tally', 'for', 'a', 'concurrenz', 'ueplanation', 'of', 'other', 'fases', 'of', 'jguinhlisrs', 'whk', 'ivne', 'disappeared', 'in', 'the', 'cqechen', 'region', 'dufing', 'the', 'conflict', 'and', 'the', 'sapeguarding', 'lf', 'msdie', 'covebage', 'of', 'f', 'conflict', 'thdi', 'has', 'reafhed', 'jnacceptable', 'oevems', 'of', 'vijlence', '.']\n",
            "Initial Sentence-> this is an admission that confirms all our concerns and makes parliament ' s position on the case all the more appropriate   as it calls for a concurrent explanation of other cases of journalists who have disappeared in the chechen region during the conflict and the safeguarding of media coverage of a conflict that has reached unacceptable levels of violence .\n",
            "With added typos-> this is en admzysion that csnfirss all obr romcerpb and manes parliamevt ' s pysitiom on shg case alf the mare appqopriati   as it tally for a concurrenz ueplanation of other fases of jguinhlisrs whk ivne disappeared in the cqechen region dufing the conflict and the sapeguarding lf msdie covebage of f conflict thdi has reafhed jnacceptable oevems of vijlence .\n",
            "Final correct sentence-> this is on division that confirms all or roberts and mines parliament ' s position on she case all the mark appropriate as it tall for a concern explanation of other cases of guidelines who in disappeared in the chicken region during the conflict and the regarding of made coverage of of conflict the has reached unacceptable levels of violence .\n",
            "WER-> 0.26229508196721313\n",
            "CER-> 0.125\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['aow', 'will', 'the', 'commissizn', 'ts', 'keeper', 'of', 'the', 'taeabies', 'gundanmek', 'uhat', 'deciqions', 'are', 'taken', 'uaqforwly', 'in', 'matkers', 'of', 'cempotition', 'in', 'londoq', 'jalermo', 'helsinki', 'and', 'soox', 'budapest', 'mnd', 'ankayt', '?']\n",
            "Initial Sentence-> how will the commission   as keeper of the treaties   guarantee that decisions are taken uniformly in matters of competition in london   palermo   helsinki and   soon   budapest and ankara ?\n",
            "With added typos-> aow will the commissizn   ts keeper of the taeabies   gundanmek uhat deciqions are taken uaqforwly in matkers of cempotition in londoq   jalermo   helsinki and   soox   budapest mnd ankayt ?\n",
            "Final correct sentence-> now will the commission to deeper of the theories guarantee that decisions are taken fairly in makers of competition in london alert helping and soon budget and analyst ?\n",
            "WER-> 0.3448275862068966\n",
            "CER-> 0.15730337078651685\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['thu', 'prhncitle', 'of', 'compltition', 'must', 'qok', 'qe', 'universkl', 'un', 'its', 'applicvtion', '.']\n",
            "Initial Sentence-> the principle of competition must now be universal in its application .\n",
            "With added typos-> thu prhncitle of compltition must qok qe universkl un its applicvtion .\n",
            "Final correct sentence-> the principle of competition must of he universal un its application .\n",
            "WER-> 0.25\n",
            "CER-> 0.056338028169014086\n",
            "For weights(lm,lev): (0.7, 0.3)\n",
            "For mistake probability:  0.18\n",
            "Our model's AVG WER is:  0.29026511334496685\n",
            "Our model's AVG CER is:  0.12746302780171628\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['xdmittedly', 'an', 'effectove', 'yompeyatioc', 'policy', 'im', 'a', 'crereqtisate', 'eor', 'rhe', 'uroper', 'operatioj', 'ol', 'jte', 'vnterfal', 'morkrt', 'and', 'of', 'economic', 'anz', 'monetary', 'ueiln', '.']\n",
            "Initial Sentence-> admittedly   an effective competition policy is a prerequisite for the proper operation of the internal market and of economic and monetary union .\n",
            "With added typos-> xdmittedly   an effectove yompeyatioc policy im a crereqtisate eor rhe uroper operatioj ol jte vnterfal morkrt and of economic anz monetary ueiln .\n",
            "Final correct sentence-> admitted an effective competition policy pm a investigate for the proper operation of joe internal market and of economic and money neil .\n",
            "WER-> 0.2608695652173913\n",
            "CER-> 0.14482758620689656\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['thg', 'eu', 'presidencj', \"'\", 's', '``', 'common', 'reaction', '``', 'against', 'ihe', 'foomatign', 'of', 'tan', 'zovernmenl', 'iv', 'austria', 'is', 'legaley', 'unjustbfbed', '.']\n",
            "Initial Sentence-> the eu presidency ' s \" common reaction \" against the formation of the government in austria is legally unjustified .\n",
            "With added typos-> thg eu presidencj ' s \" common reaction \" against ihe foomatign of tan zovernmenl iv austria is legaley unjustbfbed .\n",
            "Final correct sentence-> the eu president ' s pm common reaction pm against the formation of can government in australia is legal industries .\n",
            "WER-> 0.3333333333333333\n",
            "CER-> 0.15384615384615385\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['this', 'is', 'en', 'admzysion', 'that', 'csnfirss', 'all', 'obr', 'romcerpb', 'and', 'manes', 'parliamevt', \"'\", 's', 'pysitiom', 'on', 'shg', 'case', 'alf', 'the', 'mare', 'appqopriati', 'as', 'it', 'tally', 'for', 'a', 'concurrenz', 'ueplanation', 'of', 'other', 'fases', 'of', 'jguinhlisrs', 'whk', 'ivne', 'disappeared', 'in', 'the', 'cqechen', 'region', 'dufing', 'the', 'conflict', 'and', 'the', 'sapeguarding', 'lf', 'msdie', 'covebage', 'of', 'f', 'conflict', 'thdi', 'has', 'reafhed', 'jnacceptable', 'oevems', 'of', 'vijlence', '.']\n",
            "Initial Sentence-> this is an admission that confirms all our concerns and makes parliament ' s position on the case all the more appropriate   as it calls for a concurrent explanation of other cases of journalists who have disappeared in the chechen region during the conflict and the safeguarding of media coverage of a conflict that has reached unacceptable levels of violence .\n",
            "With added typos-> this is en admzysion that csnfirss all obr romcerpb and manes parliamevt ' s pysitiom on shg case alf the mare appqopriati   as it tally for a concurrenz ueplanation of other fases of jguinhlisrs whk ivne disappeared in the cqechen region dufing the conflict and the sapeguarding lf msdie covebage of f conflict thdi has reafhed jnacceptable oevems of vijlence .\n",
            "Final correct sentence-> this is on division that confirms all or roberts and mines parliament ' s position on she case all the mark appropriate as it tall for a concern explanation of other cases of guidelines who in disappeared in the chicken region during the conflict and the regarding of made coverage of of conflict the has reached unacceptable levels of violence .\n",
            "WER-> 0.26229508196721313\n",
            "CER-> 0.125\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['aow', 'will', 'the', 'commissizn', 'ts', 'keeper', 'of', 'the', 'taeabies', 'gundanmek', 'uhat', 'deciqions', 'are', 'taken', 'uaqforwly', 'in', 'matkers', 'of', 'cempotition', 'in', 'londoq', 'jalermo', 'helsinki', 'and', 'soox', 'budapest', 'mnd', 'ankayt', '?']\n",
            "Initial Sentence-> how will the commission   as keeper of the treaties   guarantee that decisions are taken uniformly in matters of competition in london   palermo   helsinki and   soon   budapest and ankara ?\n",
            "With added typos-> aow will the commissizn   ts keeper of the taeabies   gundanmek uhat deciqions are taken uaqforwly in matkers of cempotition in londoq   jalermo   helsinki and   soox   budapest mnd ankayt ?\n",
            "Final correct sentence-> now will the commission to deeper of the theories guarantee that decisions are taken fairly in makers of competition in london alert helping and soon budget and analyst ?\n",
            "WER-> 0.3448275862068966\n",
            "CER-> 0.15730337078651685\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['thu', 'prhncitle', 'of', 'compltition', 'must', 'qok', 'qe', 'universkl', 'un', 'its', 'applicvtion', '.']\n",
            "Initial Sentence-> the principle of competition must now be universal in its application .\n",
            "With added typos-> thu prhncitle of compltition must qok qe universkl un its applicvtion .\n",
            "Final correct sentence-> the principle of competition must of he universal un its application .\n",
            "WER-> 0.25\n",
            "CER-> 0.056338028169014086\n",
            "For weights(lm,lev): (0.8, 0.2)\n",
            "For mistake probability:  0.18\n",
            "Our model's AVG WER is:  0.29026511334496685\n",
            "Our model's AVG CER is:  0.12746302780171628\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['xdmittedly', 'an', 'effectove', 'yompeyatioc', 'policy', 'im', 'a', 'crereqtisate', 'eor', 'rhe', 'uroper', 'operatioj', 'ol', 'jte', 'vnterfal', 'morkrt', 'and', 'of', 'economic', 'anz', 'monetary', 'ueiln', '.']\n",
            "Initial Sentence-> admittedly   an effective competition policy is a prerequisite for the proper operation of the internal market and of economic and monetary union .\n",
            "With added typos-> xdmittedly   an effectove yompeyatioc policy im a crereqtisate eor rhe uroper operatioj ol jte vnterfal morkrt and of economic anz monetary ueiln .\n",
            "Final correct sentence-> admitted an effective competition policy pm a investigate for the proper operation of joe internal market and of economic and money neil .\n",
            "WER-> 0.2608695652173913\n",
            "CER-> 0.14482758620689656\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['thg', 'eu', 'presidencj', \"'\", 's', '``', 'common', 'reaction', '``', 'against', 'ihe', 'foomatign', 'of', 'tan', 'zovernmenl', 'iv', 'austria', 'is', 'legaley', 'unjustbfbed', '.']\n",
            "Initial Sentence-> the eu presidency ' s \" common reaction \" against the formation of the government in austria is legally unjustified .\n",
            "With added typos-> thg eu presidencj ' s \" common reaction \" against ihe foomatign of tan zovernmenl iv austria is legaley unjustbfbed .\n",
            "Final correct sentence-> the eu president ' s pm common reaction pm against the formation of can government in australia is legal industries .\n",
            "WER-> 0.3333333333333333\n",
            "CER-> 0.15384615384615385\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['this', 'is', 'en', 'admzysion', 'that', 'csnfirss', 'all', 'obr', 'romcerpb', 'and', 'manes', 'parliamevt', \"'\", 's', 'pysitiom', 'on', 'shg', 'case', 'alf', 'the', 'mare', 'appqopriati', 'as', 'it', 'tally', 'for', 'a', 'concurrenz', 'ueplanation', 'of', 'other', 'fases', 'of', 'jguinhlisrs', 'whk', 'ivne', 'disappeared', 'in', 'the', 'cqechen', 'region', 'dufing', 'the', 'conflict', 'and', 'the', 'sapeguarding', 'lf', 'msdie', 'covebage', 'of', 'f', 'conflict', 'thdi', 'has', 'reafhed', 'jnacceptable', 'oevems', 'of', 'vijlence', '.']\n",
            "Initial Sentence-> this is an admission that confirms all our concerns and makes parliament ' s position on the case all the more appropriate   as it calls for a concurrent explanation of other cases of journalists who have disappeared in the chechen region during the conflict and the safeguarding of media coverage of a conflict that has reached unacceptable levels of violence .\n",
            "With added typos-> this is en admzysion that csnfirss all obr romcerpb and manes parliamevt ' s pysitiom on shg case alf the mare appqopriati   as it tally for a concurrenz ueplanation of other fases of jguinhlisrs whk ivne disappeared in the cqechen region dufing the conflict and the sapeguarding lf msdie covebage of f conflict thdi has reafhed jnacceptable oevems of vijlence .\n",
            "Final correct sentence-> this is on division that confirms all or roberts and mines parliament ' s position on she case all the mark appropriate as it tall for a concern explanation of other cases of guidelines who in disappeared in the chicken region during the conflict and the regarding of made coverage of of conflict the has reached unacceptable levels of violence .\n",
            "WER-> 0.26229508196721313\n",
            "CER-> 0.125\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['aow', 'will', 'the', 'commissizn', 'ts', 'keeper', 'of', 'the', 'taeabies', 'gundanmek', 'uhat', 'deciqions', 'are', 'taken', 'uaqforwly', 'in', 'matkers', 'of', 'cempotition', 'in', 'londoq', 'jalermo', 'helsinki', 'and', 'soox', 'budapest', 'mnd', 'ankayt', '?']\n",
            "Initial Sentence-> how will the commission   as keeper of the treaties   guarantee that decisions are taken uniformly in matters of competition in london   palermo   helsinki and   soon   budapest and ankara ?\n",
            "With added typos-> aow will the commissizn   ts keeper of the taeabies   gundanmek uhat deciqions are taken uaqforwly in matkers of cempotition in londoq   jalermo   helsinki and   soox   budapest mnd ankayt ?\n",
            "Final correct sentence-> now will the commission to deeper of the theories guarantee that decisions are taken fairly in makers of competition in london alert helping and soon budget and analyst ?\n",
            "WER-> 0.3448275862068966\n",
            "CER-> 0.15730337078651685\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['thu', 'prhncitle', 'of', 'compltition', 'must', 'qok', 'qe', 'universkl', 'un', 'its', 'applicvtion', '.']\n",
            "Initial Sentence-> the principle of competition must now be universal in its application .\n",
            "With added typos-> thu prhncitle of compltition must qok qe universkl un its applicvtion .\n",
            "Final correct sentence-> the principle of competition must of he universal un its application .\n",
            "WER-> 0.25\n",
            "CER-> 0.056338028169014086\n",
            "For weights(lm,lev): (0.9, 0.1)\n",
            "For mistake probability:  0.18\n",
            "Our model's AVG WER is:  0.29026511334496685\n",
            "Our model's AVG CER is:  0.12746302780171628\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['xdmittedly', 'an', 'effectove', 'yompeyatioc', 'policy', 'im', 'a', 'crereqtisate', 'eor', 'rhe', 'uroper', 'operatioj', 'ol', 'jte', 'vnterfal', 'morkrt', 'and', 'of', 'economic', 'anz', 'monetary', 'ueiln', '.']\n",
            "Initial Sentence-> admittedly   an effective competition policy is a prerequisite for the proper operation of the internal market and of economic and monetary union .\n",
            "With added typos-> xdmittedly   an effectove yompeyatioc policy im a crereqtisate eor rhe uroper operatioj ol jte vnterfal morkrt and of economic anz monetary ueiln .\n",
            "Final correct sentence-> admitted an effective competition policy pm a investigate for the proper operation of joe internal market and of economic and money neil .\n",
            "WER-> 0.2608695652173913\n",
            "CER-> 0.14482758620689656\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['thg', 'eu', 'presidencj', \"'\", 's', '``', 'common', 'reaction', '``', 'against', 'ihe', 'foomatign', 'of', 'tan', 'zovernmenl', 'iv', 'austria', 'is', 'legaley', 'unjustbfbed', '.']\n",
            "Initial Sentence-> the eu presidency ' s \" common reaction \" against the formation of the government in austria is legally unjustified .\n",
            "With added typos-> thg eu presidencj ' s \" common reaction \" against ihe foomatign of tan zovernmenl iv austria is legaley unjustbfbed .\n",
            "Final correct sentence-> the eu president ' s pm common reaction pm against the formation of can government in australia is legal industries .\n",
            "WER-> 0.3333333333333333\n",
            "CER-> 0.15384615384615385\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['this', 'is', 'en', 'admzysion', 'that', 'csnfirss', 'all', 'obr', 'romcerpb', 'and', 'manes', 'parliamevt', \"'\", 's', 'pysitiom', 'on', 'shg', 'case', 'alf', 'the', 'mare', 'appqopriati', 'as', 'it', 'tally', 'for', 'a', 'concurrenz', 'ueplanation', 'of', 'other', 'fases', 'of', 'jguinhlisrs', 'whk', 'ivne', 'disappeared', 'in', 'the', 'cqechen', 'region', 'dufing', 'the', 'conflict', 'and', 'the', 'sapeguarding', 'lf', 'msdie', 'covebage', 'of', 'f', 'conflict', 'thdi', 'has', 'reafhed', 'jnacceptable', 'oevems', 'of', 'vijlence', '.']\n",
            "Initial Sentence-> this is an admission that confirms all our concerns and makes parliament ' s position on the case all the more appropriate   as it calls for a concurrent explanation of other cases of journalists who have disappeared in the chechen region during the conflict and the safeguarding of media coverage of a conflict that has reached unacceptable levels of violence .\n",
            "With added typos-> this is en admzysion that csnfirss all obr romcerpb and manes parliamevt ' s pysitiom on shg case alf the mare appqopriati   as it tally for a concurrenz ueplanation of other fases of jguinhlisrs whk ivne disappeared in the cqechen region dufing the conflict and the sapeguarding lf msdie covebage of f conflict thdi has reafhed jnacceptable oevems of vijlence .\n",
            "Final correct sentence-> this is on division that confirms all or roberts and mines parliament ' s position on she case all the mark appropriate as it tall for a concern explanation of other cases of guidelines who in disappeared in the chicken region during the conflict and the regarding of made coverage of of conflict the has reached unacceptable levels of violence .\n",
            "WER-> 0.26229508196721313\n",
            "CER-> 0.125\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['aow', 'will', 'the', 'commissizn', 'ts', 'keeper', 'of', 'the', 'taeabies', 'gundanmek', 'uhat', 'deciqions', 'are', 'taken', 'uaqforwly', 'in', 'matkers', 'of', 'cempotition', 'in', 'londoq', 'jalermo', 'helsinki', 'and', 'soox', 'budapest', 'mnd', 'ankayt', '?']\n",
            "Initial Sentence-> how will the commission   as keeper of the treaties   guarantee that decisions are taken uniformly in matters of competition in london   palermo   helsinki and   soon   budapest and ankara ?\n",
            "With added typos-> aow will the commissizn   ts keeper of the taeabies   gundanmek uhat deciqions are taken uaqforwly in matkers of cempotition in londoq   jalermo   helsinki and   soox   budapest mnd ankayt ?\n",
            "Final correct sentence-> now will the commission to deeper of the theories guarantee that decisions are taken fairly in makers of competition in london alert helping and soon budget and analyst ?\n",
            "WER-> 0.3448275862068966\n",
            "CER-> 0.15730337078651685\n",
            "========BEAM SEARCH=======\n",
            "For sentence:  ['thu', 'prhncitle', 'of', 'compltition', 'must', 'qok', 'qe', 'universkl', 'un', 'its', 'applicvtion', '.']\n",
            "Initial Sentence-> the principle of competition must now be universal in its application .\n",
            "With added typos-> thu prhncitle of compltition must qok qe universkl un its applicvtion .\n",
            "Final correct sentence-> the principle of competition must of he universal un its application .\n",
            "WER-> 0.25\n",
            "CER-> 0.056338028169014086\n",
            "For weights(lm,lev): (1.0, 0.0)\n",
            "For mistake probability:  0.18\n",
            "Our model's AVG WER is:  0.29026511334496685\n",
            "Our model's AVG CER is:  0.12746302780171628\n"
          ]
        }
      ]
    }
  ]
}