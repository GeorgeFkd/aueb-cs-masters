{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vckLF2z6Y12q",
        "outputId": "7acd84e7-0303-4949-8e9d-ef354673d69d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Collecting umap-learn[plot]\n",
            "  Downloading umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from umap-learn[plot]) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from umap-learn[plot]) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from umap-learn[plot]) (1.5.2)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn[plot]) (0.60.0)\n",
            "Collecting pynndescent>=0.5 (from umap-learn[plot])\n",
            "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from umap-learn[plot]) (4.66.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from umap-learn[plot]) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from umap-learn[plot]) (3.8.0)\n",
            "Collecting datashader (from umap-learn[plot])\n",
            "  Downloading datashader-0.16.3-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.10/dist-packages (from umap-learn[plot]) (3.6.2)\n",
            "Requirement already satisfied: holoviews in /usr/local/lib/python3.10/dist-packages (from umap-learn[plot]) (1.20.0)\n",
            "Requirement already satisfied: colorcet in /usr/local/lib/python3.10/dist-packages (from umap-learn[plot]) (3.1.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from umap-learn[plot]) (0.13.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from umap-learn[plot]) (0.24.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn[plot]) (0.43.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pynndescent>=0.5->umap-learn[plot]) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->umap-learn[plot]) (3.5.0)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh->umap-learn[plot]) (3.1.4)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh->umap-learn[plot]) (1.3.1)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh->umap-learn[plot]) (24.2)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh->umap-learn[plot]) (11.0.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh->umap-learn[plot]) (6.0.2)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.10/dist-packages (from bokeh->umap-learn[plot]) (6.3.3)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh->umap-learn[plot]) (2024.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->umap-learn[plot]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->umap-learn[plot]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->umap-learn[plot]) (2024.2)\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.10/dist-packages (from datashader->umap-learn[plot]) (2024.10.0)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from datashader->umap-learn[plot]) (1.0.0)\n",
            "Requirement already satisfied: param in /usr/local/lib/python3.10/dist-packages (from datashader->umap-learn[plot]) (2.1.1)\n",
            "Collecting pyct (from datashader->umap-learn[plot])\n",
            "  Downloading pyct-0.5.0-py2.py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from datashader->umap-learn[plot]) (2.32.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from datashader->umap-learn[plot]) (0.12.1)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.10/dist-packages (from datashader->umap-learn[plot]) (2024.10.0)\n",
            "Requirement already satisfied: panel>=1.0 in /usr/local/lib/python3.10/dist-packages (from holoviews->umap-learn[plot]) (1.5.4)\n",
            "Requirement already satisfied: pyviz-comms>=2.1 in /usr/local/lib/python3.10/dist-packages (from holoviews->umap-learn[plot]) (3.0.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->umap-learn[plot]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->umap-learn[plot]) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->umap-learn[plot]) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->umap-learn[plot]) (3.2.0)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image->umap-learn[plot]) (3.4.2)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->umap-learn[plot]) (2.36.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->umap-learn[plot]) (2024.12.12)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->umap-learn[plot]) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh->umap-learn[plot]) (3.0.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->holoviews->umap-learn[plot]) (6.2.0)\n",
            "Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->holoviews->umap-learn[plot]) (2.0.3)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->holoviews->umap-learn[plot]) (3.7)\n",
            "Requirement already satisfied: markdown-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->holoviews->umap-learn[plot]) (3.0.0)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->holoviews->umap-learn[plot]) (0.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->holoviews->umap-learn[plot]) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->umap-learn[plot]) (1.17.0)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from dask->datashader->umap-learn[plot]) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from dask->datashader->umap-learn[plot]) (3.1.0)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask->datashader->umap-learn[plot]) (2024.10.0)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from dask->datashader->umap-learn[plot]) (1.4.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask->datashader->umap-learn[plot]) (8.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->datashader->umap-learn[plot]) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->datashader->umap-learn[plot]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->datashader->umap-learn[plot]) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->datashader->umap-learn[plot]) (2024.8.30)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask->datashader->umap-learn[plot]) (3.21.0)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.4.0->dask->datashader->umap-learn[plot]) (1.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->panel>=1.0->holoviews->umap-learn[plot]) (0.5.1)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py->panel>=1.0->holoviews->umap-learn[plot]) (1.0.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py->panel>=1.0->holoviews->umap-learn[plot]) (0.1.2)\n",
            "Downloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datashader-0.16.3-py2.py3-none-any.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading umap_learn-0.5.7-py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyct-0.5.0-py2.py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyct, pynndescent, umap-learn, datashader\n",
            "Successfully installed datashader-0.16.3 pyct-0.5.0 pynndescent-0.5.13 umap-learn-0.5.7\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.17.0)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.1+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
            "Downloading torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.9 torchmetrics-1.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy\n",
        "!pip install scikit-learn\n",
        "!pip install pandas\n",
        "!pip install matplotlib\n",
        "!pip install umap-learn[plot]\n",
        "!pip install gensim\n",
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import linear_regression\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "import nltk\n",
        "import umap\n",
        "from nltk.help import upenn_tagset\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay, precision_score, average_precision_score,roc_auc_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "from nltk.corpus import wordnet,subjectivity,stopwords\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from nltk.tag.perceptron import PerceptronTagger\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
        "import re\n",
        "import string\n",
        "from tqdm import tqdm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "import torch # torch provides basic functions, from setting a random seed (for reproducability) to creating tensors.\n",
        "import torch.nn as nn # torch.nn allows us to create a neural network.\n",
        "import torch.nn.functional as F # nn.functional give us access to the activation and loss functions.\n",
        "from torch.optim import Adam # optim contains many optimizers. Here, we're using SGD, stochastic gradient descent, specifically Adam.\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt ## matplotlib allows us to draw graphs.\n",
        "import seaborn as sns ## seaborn makes it easier to draw nice-looking graphs.\n",
        "\n",
        "# Set the device to GPU if available, otherwise CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "nltk.download(\"subjectivity\")\n",
        "nltk.download('tagsets_json')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5186l55iZQ-m",
        "outputId": "34ce0194-79a0-4110-b57b-d94a729bdd52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package subjectivity to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data] Downloading package tagsets_json to /root/nltk_data...\n",
            "[nltk_data]   Unzipping help/tagsets_json.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def nltk_pos_tagger(nltk_tag):\n",
        "    if nltk_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif nltk_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif nltk_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif nltk_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "I2nDYfRaZW6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "def tokenize_samples(samples):\n",
        "    tokenized_samples = []\n",
        "    for sample in samples:\n",
        "        tokens = []\n",
        "        # Split text into sentences\n",
        "        sentences = sent_tokenize(sample)\n",
        "        for sent in sentences:\n",
        "            # Tokenize each sentence into words\n",
        "            words = word_tokenize(sent)\n",
        "            for word in words:\n",
        "                # Filter out stopwords and unwanted tokens\n",
        "                if '\\n' in word or \"\\t\" in word or \"--\" in word or \"*\" in word or word.lower() in stop_words:\n",
        "                    continue\n",
        "                if word.strip():\n",
        "                    # Process the token and add to list\n",
        "                    tokens.append(word.replace('\"', \"'\").strip().lower())\n",
        "        tokenized_samples.append(tokens)\n",
        "\n",
        "    return tokenized_samples"
      ],
      "metadata": {
        "id": "gIjyTxZpa8qP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data_of_subj_obj():\n",
        "    print(subjectivity.categories())\n",
        "# print(subjectivity.sents(categories=\"subj\"))\n",
        "    subjective_sentences = subjectivity.sents(categories=\"subj\")\n",
        "    objective_sentences = subjectivity.sents(categories=\"obj\")\n",
        "\n",
        "    data_with_labels = []\n",
        "    assert(len(subjective_sentences) == len(objective_sentences))\n",
        "    for i in range(len(subjective_sentences)):\n",
        "        obj_sentence = objective_sentences[i]\n",
        "        subj_sentence = subjective_sentences[i]\n",
        "        data_with_labels.append({\"label\":\"obj\",\"sentence\":obj_sentence})\n",
        "        data_with_labels.append({\"label\":\"subj\",\"sentence\":subj_sentence})\n",
        "\n",
        "    # print(upenn_tagset()) -> Μέρη του λόγου σε προτάσεις και σε τι κλήση κλπ βρίσκονται\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tagger = PerceptronTagger()\n",
        "    docs = []\n",
        "    labels = []\n",
        "    for doc in tqdm(data_with_labels):\n",
        "        sentence = \" \".join(doc[\"sentence\"])\n",
        "        label = doc[\"label\"]\n",
        "        document = re.sub(r'\\W', ' ', str(sentence))\n",
        "\n",
        "        document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
        "\n",
        "        document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
        "\n",
        "        document = document.lower()\n",
        "\n",
        "        document = document.split()\n",
        "\n",
        "        doc_pos = [x[1] for x in tagger.tag(document)]\n",
        "\n",
        "        document = \\\n",
        "            [lemmatizer.lemmatize(token, pos=nltk_pos_tagger(pos_tag)) \\\n",
        "                if nltk_pos_tagger(pos_tag) != None else lemmatizer.lemmatize(token) \\\n",
        "            for token, pos_tag in zip(document, doc_pos)]\n",
        "\n",
        "        document = ' '.join(document)\n",
        "\n",
        "        docs.append(document)\n",
        "        value_of_label = 0 if label == \"subj\" else 1\n",
        "        labels.append(value_of_label)\n",
        "        # labels.append(label)\n",
        "    # print(docs)\n",
        "    print(len(subjective_sentences),len(objective_sentences))\n",
        "    return docs,labels"
      ],
      "metadata": {
        "id": "L9mafukPbrIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs,labels = prepare_data_of_subj_obj()\n",
        "X_train_val,X_test,y_train_val,y_test = train_test_split(docs, labels, test_size=0.3, random_state=1924)\n",
        "X_train,X_val,y_train,y_val = train_test_split(X_train_val,y_train_val,test_size=0.2,random_state=1924)\n",
        "\n",
        "print('Train samples: {}'.format(len(X_train)))\n",
        "print('Val samples: {}'.format(len(X_val)))\n",
        "print('Test samples: {}'.format(len(X_test)))\n",
        "\n",
        "X_train_tokenized = tokenize_samples(X_train)\n",
        "X_val_tokenized = tokenize_samples(X_val)\n",
        "X_test_tokenized = tokenize_samples(X_test)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96RmW7N2cUoL",
        "outputId": "19536f6a-5e2d-4033-f9eb-983978889672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['obj', 'subj']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:45<00:00, 221.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5000 5000\n",
            "Train samples: 5600\n",
            "Val samples: 1400\n",
            "Test samples: 3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def svd_feature_extraction_from_data(train,val,test):\n",
        "\n",
        "    vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features = 5000, sublinear_tf=True)\n",
        "\n",
        "    X_train_tfidf = vectorizer.fit_transform([\" \".join(x) for x in X_train_tokenized])\n",
        "    X_val_tfidf = vectorizer.transform([\" \".join(x) for x in X_val_tokenized])\n",
        "    X_test_tfidf = vectorizer.transform([\" \".join(x) for x in X_test_tokenized])\n",
        "\n",
        "    # we use SVD to not change our MLP tf_idf model\n",
        "    svd = TruncatedSVD(n_components=300, random_state=4321)\n",
        "    X_train_svd = svd.fit_transform(X_train_tfidf)\n",
        "    X_val_svd = svd.transform(X_val_tfidf)\n",
        "    X_test_svd = svd.transform(X_test_tfidf)\n",
        "\n",
        "    print(X_train_tfidf.shape)\n",
        "    print(X_val_tfidf.shape)\n",
        "    print(X_test_tfidf.shape)\n",
        "\n",
        "\n",
        "    return X_train_svd,X_val_svd,X_test_svd"
      ],
      "metadata": {
        "id": "gN3lmNkx04pJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_svd,X_val_svd,X_test_svd = svd_feature_extraction_from_data(X_train_tokenized,X_val_tokenized,X_test_tokenized)\n",
        "print(X_train_svd.shape)\n",
        "print(X_val_svd.shape)\n",
        "print(X_test_svd.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "felf2yhh1I7a",
        "outputId": "15bcc169-ae50-4f65-c7b2-30b3b6a7bae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5600, 5000)\n",
            "(1400, 5000)\n",
            "(3000, 5000)\n",
            "(5600, 300)\n",
            "(1400, 300)\n",
            "(3000, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_history(history):\n",
        "    # Plotting loss\n",
        "    plt.figure()\n",
        "    plt.plot(history['train_loss'], label='Training Loss')\n",
        "    plt.plot(history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Loss Over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Plotting accuracy\n",
        "    plt.figure()\n",
        "    plt.plot(history['train_accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Accuracy Over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Plotting F1 score\n",
        "    plt.figure()\n",
        "    plt.plot(history['train_f1_score'], label='Training F1 Score')\n",
        "    plt.plot(history['val_f1_score'], label='Validation F1 Score')\n",
        "    plt.title('F1 Score Over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('F1 Score')\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "QiAme-0d1V61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_histories(histories,hyper_parameters):\n",
        "    # global hyper_parameters\n",
        "    # Plotting loss\n",
        "    colors = [(\"lightgreen\",\"green\"),(\"lightblue\",\"blue\"),(\"pink\",\"red\")]\n",
        "    plt.figure()\n",
        "    for (index,history) in enumerate(histories):\n",
        "      plt.plot(history['train_loss'], label=f'Training Loss {hyper_parameters[index][0],hyper_parameters[index][1],hyper_parameters[index][2]}',color=colors[index][0])\n",
        "      plt.plot(history['val_loss'], label=f'Validation Loss {hyper_parameters[index][0],hyper_parameters[index][1],hyper_parameters[index][2]}',color=colors[index][1])\n",
        "\n",
        "    plt.title('Loss Over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(loc=(0.42,0.2))\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    for (index,history) in enumerate(histories):\n",
        "        plt.plot(history['train_accuracy'], label=f'Training Accuracy {hyper_parameters[index][0],hyper_parameters[index][1],hyper_parameters[index][2]}',color=colors[index][0])\n",
        "        plt.plot(history['val_accuracy'], label=f'Validation Accuracy {hyper_parameters[index][0],hyper_parameters[index][1],hyper_parameters[index][2]}',color=colors[index][1])\n",
        "    plt.title('Accuracy Over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    for (index,history) in enumerate(histories):\n",
        "        plt.plot(history['train_f1_score'], label=f'Training Accuracy {hyper_parameters[index][0],hyper_parameters[index][1],hyper_parameters[index][2]}',color=colors[index][0])\n",
        "        plt.plot(history['val_f1_score'], label=f'Validation Accuracy {hyper_parameters[index][0],hyper_parameters[index][1],hyper_parameters[index][2]}',color=colors[index][1])\n",
        "    plt.title('F1 Score Over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('F1 Score')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "RJ18Dwtt1ern"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "word2vec = api.load('word2vec-google-news-300')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "9v3RTQvO1nDK",
        "outputId": "edb224b7-86b6-454c-b07e-25aa32211ef3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=====---------------------------------------------] 10.4% 172.8/1662.8MB downloaded"
          ]
        },
        {
          "output_type": "error",
          "ename": "ContentTooShortError",
          "evalue": "<urlopen error retrieval incomplete: got only 181137670 out of 1743563840 bytes>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mContentTooShortError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ca3df1e20e45>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mword2vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'word2vec-google-news-300'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/downloader.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, return_path)\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0m_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/downloader.py\u001b[0m in \u001b[0;36m_download\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{fname}.gz\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0mdst_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreporthook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_progress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_calculate_md5_checksum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_get_checksum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mread\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         raise ContentTooShortError(\n\u001b[0m\u001b[1;32m    281\u001b[0m             \u001b[0;34m\"retrieval incomplete: got only %i out of %i bytes\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             % (read, size), result)\n",
            "\u001b[0;31mContentTooShortError\u001b[0m: <urlopen error retrieval incomplete: got only 181137670 out of 1743563840 bytes>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 100\n",
        "MAX_TOKENS_FOR_VOCABULARY = 100000\n",
        "\n",
        "# Build vocabulary from tokens in X_train_tokenized\n",
        "all_tokens = [token for sentence in X_train_tokenized for token in sentence]\n",
        "token_counts = Counter(all_tokens)\n",
        "\n",
        "# Initialize vocabulary with special tokens <pad> and <unk>\n",
        "vocab = {\"<pad>\": 0, \"<unk>\": 1}\n",
        "\n",
        "# Sort tokens by frequency in descending order and add to vocab starting from 2\n",
        "for i, (token, _) in enumerate(token_counts.most_common(MAX_TOKENS_FOR_VOCABULARY), start=2):\n",
        "    vocab[token] = i\n",
        "\n",
        "# Encode and pad each sentence\n",
        "def encode_sentence(sentence, vocab, max_length=100):\n",
        "    # Map each token to its vocabulary ID or <unk> if not in vocab\n",
        "    encoded = [vocab.get(token, vocab[\"<unk>\"]) for token in sentence]\n",
        "    # Pad or truncate to max_length\n",
        "    return encoded[:max_length] + [vocab[\"<pad>\"]] * max(0, max_length - len(encoded))\n",
        "\n",
        "# Apply encoding and padding to each sentence in X_train_tokenized\n",
        "train_data = [encode_sentence(sentence, vocab, MAX_SEQUENCE_LENGTH) for sentence in X_train_tokenized]\n",
        "val_data = [encode_sentence(sentence, vocab, MAX_SEQUENCE_LENGTH) for sentence in X_val_tokenized]\n",
        "test_data = [encode_sentence(sentence, vocab, MAX_SEQUENCE_LENGTH) for sentence in X_test_tokenized]"
      ],
      "metadata": {
        "id": "_BuT4MIF171t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 300\n",
        "# from our data it probably does not need more than 1.5k\n",
        "MAX_WORDS = 100_000\n",
        "MAX_SEQUENCE_LENGTH = 300\n",
        "embedding_matrix = np.zeros((MAX_WORDS+2, EMBEDDING_DIM))\n",
        "\n",
        "count = 0\n",
        "for word, i in vocab.items():\n",
        "    if i > MAX_WORDS:\n",
        "            continue\n",
        "    try:\n",
        "        embedding_matrix[i] = word2vec[word]\n",
        "        count+=1\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "#Return the number of the elements that are non-zero.\n",
        "print(len(np.unique(np.nonzero(embedding_matrix)[0])))\n",
        "print(count)\n",
        "\n",
        "print(embedding_matrix.shape)"
      ],
      "metadata": {
        "id": "q7AZp7m62O59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train[:5],y_val[:5],y_test[:5])"
      ],
      "metadata": {
        "id": "E_4AKCBlA8HW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TensorDataset(torch.tensor(train_data, dtype = torch.long), torch.tensor(y_train, dtype = torch.long))\n",
        "val_dataset = TensorDataset(torch.tensor(val_data, dtype = torch.long), torch.tensor(y_val, dtype = torch.long))\n",
        "test_dataset = TensorDataset(torch.tensor(test_data, dtype = torch.long), torch.tensor(y_test, dtype = torch.long))\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "# Create DataLoader for each dataset\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "# _,labels_of_data = prepare_data_of_subj_obj()\n",
        "print(train_dataset[:5])"
      ],
      "metadata": {
        "id": "sCEfnDJq5lqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper-Prameters\n",
        "FILTERS = 128  # the dimensionality of the output space (i.e. the number of output filters in the convolution)\n",
        "KERNEL = 3  # the length of the 1D convolution window, in NLP tasks it is looking at Trigrams\n",
        "DENSE = 128\n",
        "\n",
        "N_CLASSES = 2\n",
        "EMBEDDING_DIM = 300\n",
        "MAX_WORDS = 100_000\n",
        "MAX_SEQUENCE_LENGTH = 250\n",
        "\n",
        "class Stacked_CNN(nn.Module):\n",
        "    def __init__(self, input_dim, n_classes, dense, filters, kernel, matrix_embeddings = None,dropout=0.2):\n",
        "        super(Stacked_CNN, self).__init__()\n",
        "\n",
        "        # dimensions\n",
        "        self.input_dim = input_dim\n",
        "        self.n_classes = n_classes\n",
        "        self.filters = filters\n",
        "        self.kernel = kernel\n",
        "        self.dense = dense\n",
        "\n",
        "        # Embedding layer\n",
        "        if matrix_embeddings is not None:\n",
        "            self.embedding_layer = nn.Embedding(num_embeddings = MAX_WORDS + 2, embedding_dim = EMBEDDING_DIM, padding_idx=0).from_pretrained(matrix_embeddings)\n",
        "            self.embedding_layer.requires_grad = False # Don't change the embedding matrix\n",
        "        else:\n",
        "            self.embedding_layer = nn.Embedding(num_embeddings = MAX_WORDS + 2, embedding_dim = EMBEDDING_DIM, padding_idx=0)\n",
        "            self.embedding_layer.requires_grad = True # Learn the embedding matrix\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels = self.input_dim, out_channels=self.filters, kernel_size=self.kernel, padding = \"valid\") # Padding can either be \"valid\" or \"same\". \"same\" ensures the output length remains the same\n",
        "        self.conv2 = nn.Conv1d(in_channels = self.filters, out_channels=self.filters, kernel_size=self.kernel, padding = \"valid\")   # by padding the input whereas \"valid\" doesn't pad the input hence reducing the output\n",
        "        self.conv3 = nn.Conv1d(in_channels = self.filters, out_channels=self.filters, kernel_size=self.kernel, padding = \"valid\")   # length (the amount it reduces it by is dependent on the kernel size)\n",
        "        self.conv4 = nn.Conv1d(in_channels = self.filters, out_channels=self.filters, kernel_size=self.kernel, padding = \"valid\")\n",
        "        self.conv5 = nn.Conv1d(in_channels = self.filters, out_channels=self.filters, kernel_size=self.kernel, padding = \"valid\")\n",
        "\n",
        "        self.global_max_pool = nn.AdaptiveMaxPool1d(output_size = 1)\n",
        "\n",
        "        self.dense_layer = nn.Linear(in_features = self.filters, out_features = self.dense)\n",
        "\n",
        "        self.output = nn.Linear(in_features = self.dense, out_features = self.n_classes)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # Input shape: (batch_size, sequence_length)\n",
        "        # Embedding layer\n",
        "        x = self.embedding_layer(input.long()) # (batch_size, sequence_length, embedding_dim)\n",
        "\n",
        "        # Dropout embeddings\n",
        "        x = self.dropout(x) # (batch_size, sequence_length, embedding_dim)\n",
        "\n",
        "        # Transpose x because Conv1d expects input of (batch_size, in_channels, sequence_length) where in_channels maps to our embedding_dim here\n",
        "        x = x.transpose(1, 2) # (batch_size, embedding_dim, sequence_length)\n",
        "\n",
        "        # Stack of convolutions. Note that my shapes here are specific to my kernel size which is 3. I explain where these numbers come from in the comments.\n",
        "        x = self.conv1(x) # (batch_size, filters, sequence_length - 2)             The 2 here comes from kernel_size - 1 where 1 is the stride. This number changes depending on the kernel_size\n",
        "        x = F.relu(x) # (batch_size, filters, sequence_length - 2)\n",
        "\n",
        "        x = self.conv2(x) # (batch_size, filters, sequence_length - 4)\n",
        "        x = F.relu(x) # (batch_size, filters, sequence_length - 4)\n",
        "\n",
        "        x = self.conv3(x) # (batch_size, filters, sequence_length - 6)\n",
        "        x = F.relu(x) # (batch_size, filters, sequence_length - 6)\n",
        "\n",
        "        x = self.conv4(x) # (batch_size, filters, sequence_length - 8)\n",
        "        x = F.relu(x) # (batch_size, filters, sequence_length - 8)\n",
        "\n",
        "        x = self.conv5(x) # (batch_size, filters, sequence_length - 10)\n",
        "        x = F.relu(x) # (batch_size, filters, sequence_length - 10)\n",
        "\n",
        "        # Global max pooling\n",
        "        x = self.global_max_pool(x) # (batch_size, filters, 1)\n",
        "        x = x.squeeze(2) # (batch_size, filters)\n",
        "\n",
        "        # Dense layer\n",
        "        x = self.dense_layer(x) # (batch_size, dense)\n",
        "        x = F.relu(x) # (batch_size, dense)\n",
        "\n",
        "        # Dropout\n",
        "        x = self.dropout(x) # (batch_size, dense)\n",
        "\n",
        "        # Output layer (Logits)\n",
        "        logits = self.output(x) # (batch_size, n_classes)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "Gw_rPb1O61wV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_cnn = Stacked_CNN(input_dim = EMBEDDING_DIM,\n",
        "                          n_classes = N_CLASSES,\n",
        "                          dense = DENSE,\n",
        "                          filters = FILTERS,\n",
        "                          kernel = KERNEL,\n",
        "                          matrix_embeddings = torch.tensor(embedding_matrix, dtype = torch.float))\n",
        "\n",
        "print(stacked_cnn)\n",
        "\n",
        "print(f\"Total learnable parameters: {sum(p.numel() for p in stacked_cnn.parameters() if p.requires_grad)}\")"
      ],
      "metadata": {
        "id": "iOFKU8EM8jdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import os\n",
        "\n",
        "from torchmetrics.classification import MultilabelAccuracy, MultilabelF1Score\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def train_model(model,epochs):\n",
        "    torch.manual_seed(1)\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Initialize TorchMetrics for multi-label metrics\n",
        "    # accuracy_metric = MultilabelAccuracy(num_labels=N_CLASSES, threshold=0.5, average='micro').to(device)\n",
        "    # f1_metric = MultilabelF1Score(num_labels=N_CLASSES, threshold=0.5, average='micro').to(device)\n",
        "\n",
        "    # Hyperparameters\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_model_path = None\n",
        "    early_stopping_patience = 5\n",
        "    early_stopping_counter = 0\n",
        "\n",
        "    # Training history\n",
        "    history = {\n",
        "        'train_loss': [], 'val_loss': [],\n",
        "        'train_accuracy': [], 'val_accuracy': [],\n",
        "        'train_f1_score': [], 'val_f1_score': [],\n",
        "        'train_roc_auc':[], 'val_roc_auc': []\n",
        "    }\n",
        "\n",
        "    start_training_time = time.time()\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        train_outputs = []\n",
        "        train_labels = []\n",
        "\n",
        "        # Training phase\n",
        "        for batch in train_loader:\n",
        "            features, labels = batch\n",
        "            features = features.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(features)\n",
        "\n",
        "            # Loss calculation\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            train_outputs.append(outputs)\n",
        "            train_labels.append(labels)\n",
        "\n",
        "        # Post-epoch training calculations\n",
        "        train_outputs = torch.cat(train_outputs)\n",
        "        train_labels = torch.cat(train_labels)\n",
        "\n",
        "        # Convert logits to binary predictions\n",
        "        train_predicted_classes = torch.argmax(train_outputs, dim=1)\n",
        "        # train_predicted_classes = (train_outputs.sigmoid() > 0.5).float()\n",
        "\n",
        "        # Compute metrics using TorchMetrics\n",
        "        train_accuracy = accuracy_score(train_predicted_classes, train_labels)\n",
        "        train_f1_score = f1_score(train_predicted_classes, train_labels)\n",
        "        train_auc = roc_auc_score(train_predicted_classes,train_labels)\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_accuracy'].append(train_accuracy)\n",
        "        history['train_f1_score'].append(train_f1_score)\n",
        "        history['train_roc_auc'].append(train_auc)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f}, F1 Score: {train_f1_score:.4f}\")\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_running_loss = 0.0\n",
        "        val_outputs = []\n",
        "        val_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for features, labels in val_loader:\n",
        "                features = features.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = model(features)\n",
        "\n",
        "                # Validation loss\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_running_loss += loss.item()\n",
        "\n",
        "                val_outputs.append(outputs)\n",
        "                val_labels.append(labels)\n",
        "\n",
        "        # Post-epoch validation calculations\n",
        "        val_outputs = torch.cat(val_outputs)\n",
        "        val_labels = torch.cat(val_labels)\n",
        "\n",
        "        # Convert logits to binary predictions\n",
        "        val_predicted_classes = torch.argmax(val_outputs,dim=1)\n",
        "        # val_predicted_classes = (val_outputs.sigmoid() > 0.5).float()\n",
        "\n",
        "        # Compute validation metrics using TorchMetrics\n",
        "        val_accuracy = accuracy_score(val_predicted_classes, val_labels)\n",
        "        val_f1 = f1_score(val_predicted_classes, val_labels)\n",
        "        val_auc = roc_auc_score(val_predicted_classes,val_labels)\n",
        "\n",
        "        val_loss = val_running_loss / len(val_loader)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_accuracy'].append(val_accuracy)\n",
        "        history['val_f1_score'].append(val_f1)\n",
        "        history['val_roc_auc'].append(val_auc)\n",
        "\n",
        "        print(f\"Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}, F1 Score: {val_f1:.4f}\")\n",
        "\n",
        "        # Early stopping and checkpointing\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            early_stopping_counter = 0  # Reset counter if validation improves\n",
        "\n",
        "            new_model_path = f'model_best_epoch_{epoch + 1}.pth'\n",
        "\n",
        "            # Delete the previous best model\n",
        "            if best_model_path is not None:\n",
        "                os.remove(best_model_path)\n",
        "\n",
        "            # Save the new best model\n",
        "            torch.save(model.state_dict(), new_model_path)\n",
        "            best_model_path = new_model_path\n",
        "        else:\n",
        "            early_stopping_counter += 1\n",
        "\n",
        "        # Stop training if no improvement for 5 epochs\n",
        "        if early_stopping_counter >= early_stopping_patience:\n",
        "            print(\"Early stopping triggered. No improvement in validation loss for 5 consecutive epochs.\")\n",
        "            break\n",
        "\n",
        "    print(\"Training complete!\")\n",
        "    end_training_time = time.time()\n",
        "    return model,history,best_model_path\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hYk3sy4m9C4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_matrix[:5])"
      ],
      "metadata": {
        "id": "Tj370oK3At-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyper_parameters = [(DENSE,FILTERS,KERNEL)]\n",
        "cnn_results = []\n",
        "for dense,filters,kernel in hyper_parameters:\n",
        "    model = Stacked_CNN(input_dim = EMBEDDING_DIM,\n",
        "                            n_classes = N_CLASSES,\n",
        "                            dense = dense,\n",
        "                            filters = filters,\n",
        "                            kernel = kernel,\n",
        "                            matrix_embeddings = torch.tensor(embedding_matrix, dtype = torch.float))\n",
        "    result = train_model(model,5)\n",
        "    cnn_results.append(result)"
      ],
      "metadata": {
        "id": "rDleg7ob-qQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_training_histories(list(map(lambda x: x[1],cnn_results)),hyper_parameters)"
      ],
      "metadata": {
        "id": "snhqJJDoI7lR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for pos,(model,history,best_model_path) in enumerate(cnn_results):\n",
        "    model.load_state_dict(torch.load(best_model_path, weights_only = True))\n",
        "    dense,filters,kernel = hyper_parameters[pos]\n",
        "    pred_training = model(torch.tensor(train_data,dtype=torch.long))\n",
        "    y_pred_training = torch.argmax(pred_training,dim=1)\n",
        "    print(model)\n",
        "    model_description = f\"Stacked CNN with Dense: {dense} filters: {filters} kernels {kernel}\"\n",
        "    print(f\"Results in Training Data for {model_description}\")\n",
        "    print(classification_report(y_train, y_pred_training, target_names=[\"subj\",\"obj\"]))\n",
        "\n",
        "    pred_val = model(torch.tensor(val_data,dtype=torch.long))\n",
        "    y_pred_val = torch.argmax(pred_val, dim=1)\n",
        "    print(model)\n",
        "    print(f\"Results in Validation Data for {model_description}\")\n",
        "    print(classification_report(y_val, y_pred_val, target_names=[\"subj\",\"obj\"]))\n",
        "\n",
        "    print(f'{model_description} Validation Accuracy: {accuracy_score(y_val, y_pred_val)*100:.2f}%')\n",
        "\n",
        "    predictions_test = model(torch.tensor(test_data,dtype=torch.long))\n",
        "    y_pred_test = torch.argmax(predictions_test, dim=1)\n",
        "    print(f'{model_description} Test Accuracy:{accuracy_score(y_test, y_pred_test)*100:.2f}%')\n",
        "    print(classification_report(y_test, y_pred_test, target_names=[\"subj\",\"obj\"]))"
      ],
      "metadata": {
        "id": "wVEufVlhJlFv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}